{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86fbc6d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "opts = {'data': '', \n",
    " 'data_path_filter': None, \n",
    " 'datatest': 'import_data/test/test/', \n",
    " 'datatest_path_filter': None, \n",
    " 'color_dataset': True, \n",
    " 'data_wxyz_quaterion': False, \n",
    " 'datatest_wxyz_quaterion': False, \n",
    " 'datameshes': 'import_data/test/models', \n",
    " 'modelname': 'casapose_c_gcu5', \n",
    " 'backbonename': 'resnet18', 'train_validation_split': 0.9, 'estimate_confidence': True, \n",
    " 'estimate_coords': True, 'confidence_regularization': True, 'confidence_filter_estimates': True, \n",
    " 'confidence_choose_second': False, 'mask_loss_weight': 1.0, 'vertex_loss_weight': 0.5, \n",
    " 'proxy_loss_weight': 0.015, 'keypoint_loss_weight': 0.007, 'filter_vertex_with_segmentation': True, \n",
    " 'filter_high_proxy_errors': False, 'use_bpnp_reprojection_loss': False, 'max_keypoint_pixel_error': 12.5, \n",
    " 'object': 'obj_000001,obj_000005,obj_000006,obj_000008,obj_000009,obj_000010,obj_000011,obj_000016', \n",
    " 'no_points': 9, 'workers': 0, 'prefetch': 10, 'pretrained': True, 'batchsize': 4, \n",
    " 'imagesize': (448, 448), 'imagesize_test': (480, 640), 'lr': 0.001, 'lr_decay': 0.5, 'lr_epochs': 15,\n",
    " 'lr_epochs_start': 0, 'lr_epochs_steps': [50, 75, 90], 'noise': 0.0001, 'contrast': 0.001, \n",
    " 'brightness': 0.001, 'saturation': 0.001, 'hue': 0.001, 'use_imgaug': True, 'rotation': 0.0, \n",
    " 'translation': 0.0, 'crop_factor': 0.933333333, 'epochs': 100, 'loginterval': 10, 'saveinterval': 5, \n",
    " 'validationinterval': 1, 'save_debug_batch': False, 'save_eval_batches': True, 'write_poses': False, \n",
    " 'filter_test_with_gt': False, 'min_object_size_test': 200, 'net': 'training_checkpoints', 'manualseed': 1237, \n",
    " 'outf': 'output/train_casapose_8_16_objects', \n",
    " 'evalf': 'output/train_casapose_8_16_objects/train_casapose_8_16_objects', 'gpuids': [0, 1], \n",
    " 'train_vectors_with_ground_truth': False, 'load_h5_weights': True, \n",
    " 'load_h5_filename': '../../../data/pretrained_models/result_w', \n",
    " 'copy_weights_from_backup_network': False, 'copy_weights_add_confidence_maps': False, \n",
    " 'objects_to_copy': np.array([[0, 0],\n",
    "                               [1, 1],\n",
    "                               [2, 2],\n",
    "                               [3, 3],\n",
    "                               [4, 4],\n",
    "                               [5, 5],\n",
    "                               [6, 6],\n",
    "                               [7, 7],\n",
    "                               [8, 8]]), \n",
    "        'objects_in_input_network': 8, \n",
    "        'objects_to_copy_list': 'config/objects_to_copy.csv'}\n",
    "\n",
    "class parse(object):\n",
    "    def __init__(self, var):\n",
    "        for key, value in var.items():\n",
    "            setattr(self, key, value)\n",
    "            \n",
    "opt = parse(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3129c371",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 23:36:57.649849: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-11 23:36:57.649889: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-11 23:36:58.851638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 23:36:58.852311: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-11 23:36:58.852347: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-11 23:36:58.852376: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-11 23:36:58.852405: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-04-11 23:36:58.852432: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-04-11 23:36:58.852460: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-11 23:36:58.852487: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-11 23:36:58.852515: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-04-11 23:36:58.852521: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-04-11 23:36:58.852761: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "keypoints_array = np.array([[[[[-9.7732497e-03, 3.6659201e-03, -1.4534000e-03],\n",
    "                               [3.6046398e+01, -1.4680500e+01, -4.5020599e+01],\n",
    "                               [-3.0289101e+01, -7.2402501e+00, -4.2632900e+01],\n",
    "                               [7.4425201e+00, 2.3966400e+01, -3.9362701e+01],\n",
    "                               [-4.3485899e+00, 3.6769500e+00, 4.5835800e+01],\n",
    "                               [6.2882501e-01, -3.6412800e+01, -2.7732599e+01],\n",
    "                               [-2.6754901e-01, 3.7588799e+01, -4.7640200e+00],\n",
    "                               [3.0029400e+01, -2.3939800e+01, -8.1097898e+00],\n",
    "                               [-2.8789900e+01, -1.9449200e+01, -9.0417604e+00]]],\n",
    "\n",
    "                             [[[1.6300200e-02, -2.3040799e-03, -1.1291500e-02],\n",
    "                               [5.5248199e+00, 5.4157101e+01, -9.6322701e+01],\n",
    "                               [-4.1018100e+00, 1.2732400e+01, 9.6678497e+01],\n",
    "                               [-9.1580000e+00, -4.1244202e+01, -8.7472397e+01],\n",
    "                               [7.3375401e+00, 9.0886101e+01, -1.1365300e+01],\n",
    "                               [-1.0262200e+01, -9.0547600e+01, -3.7563899e-01],\n",
    "                               [-4.7794201e+01, 1.6508699e+01, -5.6376900e+01],\n",
    "                               [4.8287998e+01, 2.4022501e+00, -6.2877899e+01],\n",
    "                               [4.6154099e+01, 1.1302400e+01, 4.9851101e+01]]],\n",
    "\n",
    "                             [[[1.7128000e-02, -4.5700101e-03, -5.3901700e-03],\n",
    "                               [2.0947300e+01, -6.1587502e+01, -5.4198200e+01],\n",
    "                               [-2.0933701e+01, 6.3563000e+01, 2.6130899e+01],\n",
    "                               [2.8901501e+01, 2.7392700e+01, -5.7568199e+01],\n",
    "                               [1.4403200e+00, -5.8665901e+01, 2.2473900e+01],\n",
    "                               [1.2946500e+01, 1.4082400e+01, 5.8292999e+01],\n",
    "                               [-2.8743299e+01, 1.6301001e+01, -5.2558300e+01],\n",
    "                               [-3.3441200e+01, -4.1310501e+01, -5.4232101e+01],\n",
    "                               [2.3869900e+01, 4.1699699e+01, 1.6587299e+01]]],\n",
    "\n",
    "                             [[[-2.4108901e-03, -6.2332200e-03, -6.3247699e-03],\n",
    "                               [1.1291000e+02, -3.4727199e+00, 9.2172699e+01],\n",
    "                               [-1.1182900e+02, 3.1709600e-02, 6.1154400e+01],\n",
    "                               [-6.2377201e+01, 1.0970700e+01, -1.0025700e+02],\n",
    "                               [4.2661201e+01, -2.4666700e+01, -9.9452499e+01],\n",
    "                               [1.0724100e+01, -3.5357201e+00, 1.0133300e+02],\n",
    "                               [-4.1970699e+01, -3.1155399e+01, 5.4645599e+01],\n",
    "                               [4.9310899e+00, 3.6434399e+01, -9.7123596e+01],\n",
    "                               [5.6840302e+01, -4.2665200e+00, 4.8058399e+01]]],\n",
    "\n",
    "                             [[[-3.4179699e-03, -9.8838797e-03, 3.9329501e-03],\n",
    "                               [4.9320702e+01, 6.2302999e+00, -4.0302898e+01],\n",
    "                               [-4.6246700e+01, 2.3396499e+00, -3.7502899e+01],\n",
    "                               [1.2448000e+01, -3.3365299e+01, -4.0734501e+01],\n",
    "                               [3.9640200e+00, 3.4297600e+01, -4.0923302e+01],\n",
    "                               [4.5272598e+01, -1.0067500e+00, 2.1399401e+01],\n",
    "                               [6.6833901e+00, -3.1548400e+00, 4.2783199e+01],\n",
    "                               [-2.3509399e+01, -2.7834400e+01, -1.9335600e+01],\n",
    "                               [-4.1355202e+01, 1.3988900e-01, 1.3391900e+00]]],\n",
    "\n",
    "                             [[[-1.7417900e-02, -4.2999300e-01, -1.3252300e-02],\n",
    "                               [-7.0443398e+01, 4.3526299e+01, 4.2999201e+00],\n",
    "                               [7.3233902e+01, 3.5586300e+01, 4.8644700e+00],\n",
    "                               [6.7131897e+01, -4.4466202e+01, -2.7725799e+00],\n",
    "                               [-7.0990898e+01, -3.6974701e+01, -1.3353300e+00],\n",
    "                               [-4.7924999e+01, 5.5036702e+00, -3.2836399e+01],\n",
    "                               [2.2584101e+01, 4.1242500e+01, 3.2724400e+01],\n",
    "                               [-2.4753901e+01, -4.0470100e+01, 3.2213699e+01],\n",
    "                               [4.7744598e+01, 4.2735401e-01, -3.1653799e+01]]],\n",
    "\n",
    "                             [[[9.9391900e-03, -1.1459400e-02, 6.8359398e-03],\n",
    "                               [-9.1147299e+00, -3.1402399e+01, -8.5777802e+01],\n",
    "                               [9.7676700e-01, 2.9348700e+00, 8.6390404e+01],\n",
    "                               [6.4356799e+00, 3.7870701e+01, -6.3978802e+01],\n",
    "                               [9.7071304e+00, -3.6640800e+01, -3.6885799e+01],\n",
    "                               [-1.5302700e+01, 1.4431200e+00, -4.7971500e+01],\n",
    "                               [-6.0784298e-01, -1.2160700e+01, 4.3689098e+01],\n",
    "                               [1.7079800e+01, 1.9666600e+00, -8.3763802e+01],\n",
    "                               [-4.1084499e+00, 3.5197800e+01, -2.3239799e+01]]],\n",
    "\n",
    "                             [[[-6.8052673e-01, 4.3509445e+00, -1.5487452e+00],\n",
    "                               [5.8407185e+01, -8.2160988e+01, -1.2327696e+01],\n",
    "                               [-9.1078697e+01, -4.6658367e+01, -7.3403926e+00],\n",
    "                               [9.6684196e+01, 1.5651445e+01, 2.6858237e+00],\n",
    "                               [-7.8112083e+01, 6.0135139e+01, -6.0886226e+00],\n",
    "                               [3.1481721e+00, 9.0496506e+01, -1.1837043e+01],\n",
    "                               [-1.9831656e+01, -8.0089989e+01, -2.5694869e+00],\n",
    "                               [5.0045956e+01, 5.1196590e+01, -1.4792501e+01],\n",
    "                               [2.3459833e+01, -4.9363476e+01, 1.9859182e+01]]]]],\n",
    "                           )\n",
    "cuboids_array = np.array([[[[-37.92094, -38.788555, -45.88129],\n",
    "                      [-37.92094, -38.788555, 45.87838],\n",
    "                      [-37.92094, 38.795883, -45.88129],\n",
    "                      [-37.92094, 38.795883, 45.87838],\n",
    "                      [37.901394, -38.788555, -45.88129],\n",
    "                      [37.901394, -38.788555, 45.87838],\n",
    "                      [37.901394, 38.795883, -45.88129],\n",
    "                      [37.901394, 38.795883, 45.87838]]],\n",
    "\n",
    "                    [[[-50.35713, -90.89071, -96.8516],\n",
    "                      [-50.35713, -90.89071, 96.82902],\n",
    "                      [-50.35713, 90.8861, -96.8516],\n",
    "                      [-50.35713, 90.8861, 96.82902],\n",
    "                      [50.38973, -90.89071, -96.8516],\n",
    "                      [50.38973, -90.89071, 96.82902],\n",
    "                      [50.38973, 90.8861, -96.8516],\n",
    "                      [50.38973, 90.8861, 96.82902]]],\n",
    "\n",
    "                    [[[-33.44303, -63.791, -58.71809],\n",
    "                      [-33.44303, -63.791, 58.707314],\n",
    "                      [-33.44303, 63.781857, -58.71809],\n",
    "                      [-33.44303, 63.781857, 58.707314],\n",
    "                      [33.47729, -63.791, -58.71809],\n",
    "                      [33.47729, -63.791, 58.707314],\n",
    "                      [33.47729, 63.781857, -58.71809],\n",
    "                      [33.47729, 63.781857, 58.707314]]],\n",
    "\n",
    "                    [[[-114.72308, -37.718895, -103.983604],\n",
    "                      [-114.72308, -37.718895, 103.97095],\n",
    "                      [-114.72308, 37.706425, -103.983604],\n",
    "                      [-114.72308, 37.706425, 103.97095],\n",
    "                      [114.71827, -37.718895, -103.983604],\n",
    "                      [114.71827, -37.718895, 103.97095],\n",
    "                      [114.71827, 37.706425, -103.983604],\n",
    "                      [114.71827, 37.706425, 103.97095]]],\n",
    "\n",
    "                    [[[-52.200897, -38.71081, -42.8214],\n",
    "                      [-52.200897, -38.71081, 42.82927],\n",
    "                      [-52.200897, 38.691044, -42.8214],\n",
    "                      [-52.200897, 38.691044, 42.82927],\n",
    "                      [52.194057, -38.71081, -42.8214],\n",
    "                      [52.194057, -38.71081, 42.82927],\n",
    "                      [52.194057, 38.691044, -42.8214],\n",
    "                      [52.194057, 38.691044, 42.82927]]],\n",
    "\n",
    "                    [[[-75.0917, -54.39756, -34.629425],\n",
    "                      [-75.0917, -54.39756, 34.602924],\n",
    "                      [-75.0917, 53.53758, -34.629425],\n",
    "                      [-75.0917, 53.53758, 34.602924],\n",
    "                      [75.05686, -54.39756, -34.629425],\n",
    "                      [75.05686, -54.39756, 34.602924],\n",
    "                      [75.05686, 53.53758, -34.629425],\n",
    "                      [75.05686, 53.53758, 34.602924]]],\n",
    "\n",
    "                    [[[-18.320473, -38.923126, -86.376724],\n",
    "                      [-18.320473, -38.923126, 86.3904],\n",
    "                      [-18.320473, 38.900208, -86.376724],\n",
    "                      [-18.320473, 38.900208, 86.3904],\n",
    "                      [18.340351, -38.923126, -86.376724],\n",
    "                      [18.340351, -38.923126, 86.3904],\n",
    "                      [18.340351, 38.900208, -86.376724],\n",
    "                      [18.340351, 38.900208, 86.3904]]],\n",
    "\n",
    "                    [[[-98.16961, -85.56149, -32.21377],\n",
    "                      [-98.16961, -85.56149, 29.116282],\n",
    "                      [-98.16961, 94.26338, -32.21377],\n",
    "                      [-98.16961, 94.26338, 29.116282],\n",
    "                      [96.808556, -85.56149, -32.21377],\n",
    "                      [96.808556, -85.56149, 29.116282],\n",
    "                      [96.808556, 94.26338, -32.21377],\n",
    "                      [96.808556, 94.26338, 29.116282]]]])\n",
    "\n",
    "synthetic_image = False\n",
    "keypoints = tf.convert_to_tensor(keypoints_array, dtype=tf.float32)\n",
    "cuboids = tf.convert_to_tensor(cuboids_array, dtype=tf.float32)\n",
    "if synthetic_image:\n",
    "    camera_matrix = np.array([[[572.4114, 0., 325.2611],\n",
    "                               [0., 573.57043, 242.049],\n",
    "                               [0., 0., 1.]]])\n",
    "else:  # Samsung S22, 640x480\n",
    "    camera_matrix = [[[345.5395354181145, 0, 319.4688241083385],\n",
    "                     [0, 345.25337576116874, 237.47917860129158],\n",
    "                     [0, 0, 1]]]\n",
    "camera_matrix = tf.convert_to_tensor(camera_matrix, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c86c7564",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=\n",
       "array([[[345.53952,   0.     , 319.4688 ],\n",
       "        [  0.     , 345.2534 , 237.47917],\n",
       "        [  0.     ,   0.     ,   1.     ]]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af1fb24e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TEST WITH STATIC CUBOID / KEYPOINT AND REMAINING ARE SAME\n",
    "# TEST WITH IMAGEONLYDATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62bac3ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/gpu:0']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.extend([\".\", \"..\"])  # adds the folder from which you call the script\n",
    "os.environ[\"CASAPOSE_INFERENCE\"] = \"True\"\n",
    "\n",
    "from casapose.data_handler.image_only_dataset import ImageOnlyDataset\n",
    "from casapose.pose_estimation.pose_evaluation import poses_pnp\n",
    "from casapose.pose_estimation.voting_layers_2d import CoordLSVotingWeighted\n",
    "from casapose.pose_models.tfkeras import Classifiers\n",
    "from casapose.utils.config_parser import parse_config\n",
    "\n",
    "\n",
    "if not os.path.exists(opt.evalf):\n",
    "    os.makedirs(opt.evalf)\n",
    "\n",
    "checkpoint_path = opt.outf + \"/\" + opt.net\n",
    "\n",
    "frozen_path = opt.outf + \"/frozen_model\"\n",
    "img_out_path = opt.outf + \"/control_output\"\n",
    "\n",
    "\n",
    "def create_dir(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "\n",
    "create_dir(img_out_path)\n",
    "\n",
    "# save the hyper parameters passed\n",
    "with open(opt.evalf + \"/header_eval.txt\", \"w\") as file:\n",
    "    file.write(str(opt))\n",
    "\n",
    "# set the manual seed.\n",
    "np.random.seed(opt.manualseed)\n",
    "tf.random.set_seed(opt.manualseed)\n",
    "\n",
    "test_dataset = None\n",
    "\n",
    "device_ids = []\n",
    "if len(opt.gpuids) == 1 and opt.gpuids[0] < 0:\n",
    "    device_ids.append(\"/cpu:0\")\n",
    "else:\n",
    "    device_ids.append(\"/gpu:{}\".format(opt.gpuids[0]))\n",
    "print(device_ids)\n",
    "\n",
    "objectsofinterest = [x.strip() for x in opt.object.split(\",\")]\n",
    "no_objects = len(objectsofinterest)\n",
    "separated_vectorfields = opt.modelname == \"pvnet\"\n",
    "\n",
    "testingdata = None\n",
    "normal_imgs = [0.5, 0.5]\n",
    "\n",
    "use_split = False\n",
    "if opt.data == opt.datatest:\n",
    "    print(\"split datasets with ratio {}\".format(opt.train_validation_split))\n",
    "    use_split = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb10e4e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a844c011",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/inference5_resized/'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opt.datatest = 'data/inference_resized/'\n",
    "# opt.datatest = 'data/inference2_resized/'\n",
    "# opt.datatest = 'data/inference3_resized/'\n",
    "# opt.datatest = 'data/inference4_resized/'\n",
    "opt.datatest = 'data/inference5_resized/'\n",
    "# opt.datatest = 'data/inference6_resized/'\n",
    "\n",
    "\n",
    "# path_out = 'data/inference_output'\n",
    "# path_out = 'data/inference2_output'\n",
    "# path_out = 'data/inference3_output'\n",
    "# path_out = 'data/inference4_output'\n",
    "path_out = 'data/inference5_output'\n",
    "# path_out = 'data/inference6_output'\n",
    "\n",
    "opt.datatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78069020",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ImageOnlyDataset(root=opt.datatest)\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c66d6e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m testingdata, test_batches \u001b[38;5;241m=\u001b[39m \u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/w251_final_project/edge/casapose/data_handler/image_only_dataset.py:97\u001b[0m, in \u001b[0;36mImageOnlyDataset.generate_dataset\u001b[0;34m(self, batchsize)\u001b[0m\n\u001b[1;32m     93\u001b[0m     input_size \u001b[38;5;241m=\u001b[39m [first_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], first_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], first_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]]\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset_out, input_size\n\u001b[0;32m---> 97\u001b[0m dataset_out, input_size \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_base_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m data_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs) \u001b[38;5;241m-\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs) \u001b[38;5;241m%\u001b[39m batchsize)\n\u001b[1;32m    100\u001b[0m epoch_batches \u001b[38;5;241m=\u001b[39m data_size \u001b[38;5;241m/\u001b[39m batchsize\n",
      "File \u001b[0;32m~/w251_final_project/edge/casapose/data_handler/image_only_dataset.py:92\u001b[0m, in \u001b[0;36mImageOnlyDataset.generate_dataset.<locals>.create_base_dataset\u001b[0;34m(imgs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     path_list\u001b[38;5;241m.\u001b[39mappend(path)\n\u001b[1;32m     91\u001b[0m dataset_out \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((path_list))\n\u001b[0;32m---> 92\u001b[0m first_img \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mdecode_image(tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_file(\u001b[43mpath_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[1;32m     93\u001b[0m input_size \u001b[38;5;241m=\u001b[39m [first_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], first_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], first_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]]\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset_out, input_size\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "testingdata, test_batches = test_dataset.generate_dataset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d3dbe08",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<casapose.data_handler.image_only_dataset.ImageOnlyDataset at 0x1ef7fbb5370>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ec8bcf2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3093638",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, 240, 320, 64) dtype=float32 (created by layer 'relu0')>, <KerasTensor: shape=(None, 120, 160, 64) dtype=float32 (created by layer 'stage2_unit1_relu1')>, <KerasTensor: shape=(None, 60, 80, 128) dtype=float32 (created by layer 'stage3_unit1_relu1')>, <KerasTensor: shape=(None, 60, 80, 256) dtype=float32 (created by layer 'stage4_unit1_relu1')>, <KerasTensor: shape=(None, 60, 80, 512) dtype=float32 (created by layer 'relu1')>]\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " data (InputLayer)              [(None, 480, 640, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model (Functional)             [(None, 240, 320, 6  11186889    ['data[0][0]']                   \n",
      "                                4),                                                               \n",
      "                                 (None, 120, 160, 6                                               \n",
      "                                4),                                                               \n",
      "                                 (None, 60, 80, 128                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 60, 80, 256                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 60, 80, 512                                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_18 (ZeroPadding  (None, 62, 82, 512)  0          ['model[0][4]']                  \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " pv_block_1_conv2d (Conv2D)     (None, 60, 80, 256)  1179648     ['zero_padding2d_18[0][0]']      \n",
      "                                                                                                  \n",
      " pv_block_1_bn (SyncBatchNormal  (None, 60, 80, 256)  1024       ['pv_block_1_conv2d[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " pv_block_1_relu (Activation)   (None, 60, 80, 256)  0           ['pv_block_1_bn[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 60, 80, 384)  0           ['pv_block_1_relu[0][0]',        \n",
      "                                                                  'model[0][2]']                  \n",
      "                                                                                                  \n",
      " zero_padding2d_19 (ZeroPadding  (None, 62, 82, 384)  0          ['concatenate[0][0]']            \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " pv_block_2_conv2d (Conv2D)     (None, 60, 80, 128)  442368      ['zero_padding2d_19[0][0]']      \n",
      "                                                                                                  \n",
      " pv_block_2_bn (SyncBatchNormal  (None, 60, 80, 128)  512        ['pv_block_2_conv2d[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 60, 80, 128)  0           ['pv_block_2_bn[0][0]']          \n",
      "                                                                                                  \n",
      " pv_block_2_relu1 (Activation)  (None, 60, 80, 128)  0           ['pv_block_2_bn[0][0]']          \n",
      "                                                                                                  \n",
      " pv_block_2_relu2 (Activation)  (None, 60, 80, 128)  0           ['tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      " subtract (Subtract)            (None, 60, 80, 128)  0           ['pv_block_2_relu1[0][0]',       \n",
      "                                                                  'pv_block_2_relu2[0][0]']       \n",
      "                                                                                                  \n",
      " pv_block_2_upsampling (UpSampl  (None, 120, 160, 12  0          ['subtract[0][0]']               \n",
      " ing2D)                         8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 120, 160, 19  0           ['pv_block_2_upsampling[0][0]',  \n",
      "                                2)                                'model[0][1]']                  \n",
      "                                                                                                  \n",
      " zero_padding2d_20 (ZeroPadding  (None, 122, 162, 19  0          ['concatenate_1[0][0]']          \n",
      " 2D)                            2)                                                                \n",
      "                                                                                                  \n",
      " pv_block_3_conv2d (Conv2D)     (None, 120, 160, 64  110592      ['zero_padding2d_20[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_3_bn (SyncBatchNormal  (None, 120, 160, 64  256        ['pv_block_3_conv2d[0][0]']      \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 120, 160, 64  0          ['pv_block_3_bn[0][0]']          \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_3_relu1 (Activation)  (None, 120, 160, 64  0           ['pv_block_3_bn[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_3_relu2 (Activation)  (None, 120, 160, 64  0           ['tf.math.multiply_1[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " subtract_1 (Subtract)          (None, 120, 160, 64  0           ['pv_block_3_relu1[0][0]',       \n",
      "                                )                                 'pv_block_3_relu2[0][0]']       \n",
      "                                                                                                  \n",
      " pv_block_3_upsampling (UpSampl  (None, 240, 320, 64  0          ['subtract_1[0][0]']             \n",
      " ing2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 240, 320, 12  0           ['pv_block_3_upsampling[0][0]',  \n",
      "                                8)                                'model[0][0]']                  \n",
      "                                                                                                  \n",
      " zero_padding2d_21 (ZeroPadding  (None, 242, 322, 12  0          ['concatenate_2[0][0]']          \n",
      " 2D)                            8)                                                                \n",
      "                                                                                                  \n",
      " pv_block_4_conv2d (Conv2D)     (None, 240, 320, 32  36864       ['zero_padding2d_21[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_4_bn (SyncBatchNormal  (None, 240, 320, 32  128        ['pv_block_4_conv2d[0][0]']      \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, 240, 320, 32  0          ['pv_block_4_bn[0][0]']          \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_4_relu1 (Activation)  (None, 240, 320, 32  0           ['pv_block_4_bn[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_4_relu2 (Activation)  (None, 240, 320, 32  0           ['tf.math.multiply_2[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " subtract_2 (Subtract)          (None, 240, 320, 32  0           ['pv_block_4_relu1[0][0]',       \n",
      "                                )                                 'pv_block_4_relu2[0][0]']       \n",
      "                                                                                                  \n",
      " pv_block_4_upsampling (UpSampl  (None, 480, 640, 32  0          ['subtract_2[0][0]']             \n",
      " ing2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 480, 640, 35  0           ['pv_block_4_upsampling[0][0]',  \n",
      "                                )                                 'data[0][0]']                   \n",
      "                                                                                                  \n",
      " zero_padding2d_22 (ZeroPadding  (None, 482, 642, 35  0          ['concatenate_3[0][0]']          \n",
      " 2D)                            )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_5_conv2d (Conv2D)     (None, 480, 640, 32  10080       ['zero_padding2d_22[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_5_bn (SyncBatchNormal  (None, 480, 640, 32  128        ['pv_block_5_conv2d[0][0]']      \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, 480, 640, 32  0          ['pv_block_5_bn[0][0]']          \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_5_relu1 (Activation)  (None, 480, 640, 32  0           ['pv_block_5_bn[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_5_relu2 (Activation)  (None, 480, 640, 32  0           ['tf.math.multiply_3[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " subtract_3 (Subtract)          (None, 480, 640, 32  0           ['pv_block_5_relu1[0][0]',       \n",
      "                                )                                 'pv_block_5_relu2[0][0]']       \n",
      "                                                                                                  \n",
      " pv_final_conv_segmentation (Co  (None, 480, 640, 9)  288        ['subtract_3[0][0]']             \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None, 480, 640, 9)  0          ['pv_final_conv_segmentation[0][0\n",
      " )                                                               ]']                              \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 480, 640, 9)  0           ['tf.math.multiply_4[0][0]']     \n",
      "                                                                                                  \n",
      " tf.stop_gradient (TFOpLambda)  (None, 480, 640, 9)  0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " segmentation_half_size (HalfSi  (None, 240, 320, 9)  0          ['tf.stop_gradient[0][0]']       \n",
      " ze)                                                                                              \n",
      "                                                                                                  \n",
      " segmentation_quater_size (Half  (None, 120, 160, 9)  0          ['segmentation_half_size[0][0]'] \n",
      " Size)                                                                                            \n",
      "                                                                                                  \n",
      " segmentation_eighth_size (Half  (None, 60, 80, 9)   0           ['segmentation_quater_size[0][0]'\n",
      " Size)                                                           ]                                \n",
      "                                                                                                  \n",
      " pv_block_6_prepare_conv2d (Par  (None, 60, 80, 256)  1179648    ['model[0][4]',                  \n",
      " tialConvolution)                                                 'segmentation_eighth_size[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " pv_block_6_clade (ClassAdaptiv  (None, 60, 80, 256)  5120       ['pv_block_6_prepare_conv2d[0][0]\n",
      " eWeightedNormalization)                                         ',                               \n",
      "                                                                  'segmentation_eighth_size[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " pv_block_6_relu (Activation)   (None, 60, 80, 256)  0           ['pv_block_6_clade[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 60, 80, 384)  0           ['pv_block_6_relu[0][0]',        \n",
      "                                                                  'model[0][2]']                  \n",
      "                                                                                                  \n",
      " pv_block_7_prepare_conv2d (Par  (None, 60, 80, 128)  442368     ['concatenate_4[0][0]',          \n",
      " tialConvolution)                                                 'segmentation_eighth_size[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " pv_block_7_clade (ClassAdaptiv  (None, 60, 80, 128)  2560       ['pv_block_7_prepare_conv2d[0][0]\n",
      " eWeightedNormalization)                                         ',                               \n",
      "                                                                  'segmentation_eighth_size[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None, 60, 80, 128)  0          ['pv_block_7_clade[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pv_block_7_relu1 (Activation)  (None, 60, 80, 128)  0           ['pv_block_7_clade[0][0]']       \n",
      "                                                                                                  \n",
      " pv_block_7_relu2 (Activation)  (None, 60, 80, 128)  0           ['tf.math.multiply_5[0][0]']     \n",
      "                                                                                                  \n",
      " subtract_4 (Subtract)          (None, 60, 80, 128)  0           ['pv_block_7_relu1[0][0]',       \n",
      "                                                                  'pv_block_7_relu2[0][0]']       \n",
      "                                                                                                  \n",
      " pv_block_7_guided_upsamling (G  (None, 120, 160, 12  0          ['subtract_4[0][0]',             \n",
      " uidedUpsampling)               8)                                'segmentation_eighth_size[0][0]'\n",
      "                                                                 , 'segmentation_quater_size[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 120, 160, 19  0           ['pv_block_7_guided_upsamling[0][\n",
      "                                2)                               0]',                             \n",
      "                                                                  'model[0][1]']                  \n",
      "                                                                                                  \n",
      " pv_block_8_prepare_conv2d (Par  (None, 120, 160, 64  110592     ['concatenate_5[0][0]',          \n",
      " tialConvolution)               )                                 'segmentation_quater_size[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " pv_block_8_clade (ClassAdaptiv  (None, 120, 160, 64  1280       ['pv_block_8_prepare_conv2d[0][0]\n",
      " eWeightedNormalization)        )                                ',                               \n",
      "                                                                  'segmentation_quater_size[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None, 120, 160, 64  0          ['pv_block_8_clade[0][0]']       \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_8_relu1 (Activation)  (None, 120, 160, 64  0           ['pv_block_8_clade[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_8_relu2 (Activation)  (None, 120, 160, 64  0           ['tf.math.multiply_6[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " subtract_5 (Subtract)          (None, 120, 160, 64  0           ['pv_block_8_relu1[0][0]',       \n",
      "                                )                                 'pv_block_8_relu2[0][0]']       \n",
      "                                                                                                  \n",
      " pv_block_8_guided_upsamling (G  (None, 240, 320, 64  0          ['subtract_5[0][0]',             \n",
      " uidedUpsampling)               )                                 'segmentation_quater_size[0][0]'\n",
      "                                                                 , 'segmentation_half_size[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 240, 320, 12  0           ['pv_block_8_guided_upsamling[0][\n",
      "                                8)                               0]',                             \n",
      "                                                                  'model[0][0]']                  \n",
      "                                                                                                  \n",
      " pv_block_9_prepare_conv2d (Par  (None, 240, 320, 32  36864      ['concatenate_6[0][0]',          \n",
      " tialConvolution)               )                                 'segmentation_half_size[0][0]'] \n",
      "                                                                                                  \n",
      " pv_block_9_clade (ClassAdaptiv  (None, 240, 320, 32  640        ['pv_block_9_prepare_conv2d[0][0]\n",
      " eWeightedNormalization)        )                                ',                               \n",
      "                                                                  'segmentation_half_size[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLambda  (None, 240, 320, 32  0          ['pv_block_9_clade[0][0]']       \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_9_relu1 (Activation)  (None, 240, 320, 32  0           ['pv_block_9_clade[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_9_relu2 (Activation)  (None, 240, 320, 32  0           ['tf.math.multiply_7[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " subtract_6 (Subtract)          (None, 240, 320, 32  0           ['pv_block_9_relu1[0][0]',       \n",
      "                                )                                 'pv_block_9_relu2[0][0]']       \n",
      "                                                                                                  \n",
      " pv_block_9_guided_upsamling (G  (None, 480, 640, 32  0          ['subtract_6[0][0]',             \n",
      " uidedUpsampling)               )                                 'segmentation_half_size[0][0]', \n",
      "                                                                  'tf.stop_gradient[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 480, 640, 35  0           ['pv_block_9_guided_upsamling[0][\n",
      "                                )                                0]',                             \n",
      "                                                                  'data[0][0]']                   \n",
      "                                                                                                  \n",
      " pv_block_10_prepare_conv2d (Pa  (None, 480, 640, 32  10080      ['concatenate_7[0][0]',          \n",
      " rtialConvolution)              )                                 'tf.stop_gradient[0][0]']       \n",
      "                                                                                                  \n",
      " pv_block_10_clade (ClassAdapti  (None, 480, 640, 32  640        ['pv_block_10_prepare_conv2d[0][0\n",
      " veWeightedNormalization)       )                                ]',                              \n",
      "                                                                  'tf.stop_gradient[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLambda  (None, 480, 640, 32  0          ['pv_block_10_clade[0][0]']      \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_10_relu1 (Activation)  (None, 480, 640, 32  0          ['pv_block_10_clade[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_10_relu2 (Activation)  (None, 480, 640, 32  0          ['tf.math.multiply_8[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " subtract_7 (Subtract)          (None, 480, 640, 32  0           ['pv_block_10_relu1[0][0]',      \n",
      "                                )                                 'pv_block_10_relu2[0][0]']      \n",
      "                                                                                                  \n",
      " pv_final_conv_vertex (Conv2D)  (None, 480, 640, 27  864         ['subtract_7[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_final_concatenation (Concat  (None, 480, 640, 36  0          ['pv_final_conv_segmentation[0][0\n",
      " enate)                         )                                ]',                              \n",
      "                                                                  'pv_final_conv_vertex[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,759,433\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,759,433\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_segmentation_shape = None\n",
    "if opt.train_vectors_with_ground_truth is True:\n",
    "    input_segmentation_shape = (\n",
    "        opt.imagesize_test[0],\n",
    "        opt.imagesize_test[1],\n",
    "        1 + no_objects,\n",
    "    )\n",
    "\n",
    "\n",
    "height = opt.imagesize_test[0]\n",
    "width = opt.imagesize_test[1]\n",
    "\n",
    "CASAPose = Classifiers.get(opt.modelname)\n",
    "ver_dim = opt.no_points * 2\n",
    "if opt.modelname == \"pvnet\":\n",
    "    ver_dim = ver_dim * no_objects\n",
    "\n",
    "if opt.estimate_confidence:\n",
    "    assert separated_vectorfields is not None, \"confidence not compaitble with this model\"\n",
    "    ver_dim += opt.no_points\n",
    "\n",
    "net = CASAPose(\n",
    "    ver_dim=ver_dim,\n",
    "    seg_dim=1 + no_objects,\n",
    "    input_shape=(height, width, 3),\n",
    "    input_segmentation_shape=input_segmentation_shape,\n",
    "    weights=\"imagenet\",\n",
    "    base_model=opt.backbonename,\n",
    ")\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_path, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(network=net)  # , optimizer=optimizer)\n",
    "\n",
    "if opt.load_h5_weights is True:\n",
    "    net.load_weights(frozen_path + \"/\" + opt.load_h5_filename + \".h5\", by_name=True, skip_mismatch=True)\n",
    "\n",
    "elif opt.net != \"\":\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path)).expect_partial()\n",
    "\n",
    "for layer in net.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "net.summary()\n",
    "\n",
    "with open(opt.evalf + \"/speed_eval.csv\", \"w\") as file:\n",
    "    file.write(\"batchid,speed \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "349c694f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba00057b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def runnetwork(loader_iterator, batches, no_objects):\n",
    "    \n",
    "    @tf.function\n",
    "    def test_step(img_batch):\n",
    "        start_time = tf.timestamp()\n",
    "        \n",
    "        #keypoints = img_batch[4]\n",
    "        #camera_matrix = img_batch[5]\n",
    "        \n",
    "        # print(no_objects)\n",
    "            \n",
    "        no_points = opt.no_points\n",
    "        net_input = [tf.expand_dims(img_batch[0][0], 0)]\n",
    "        # print(net_input[0].shape)\n",
    "        output_net = net(net_input, training=False)  # all stages are present here\n",
    "        # print(output_net.shape)\n",
    "        output_seg, output_dirs, confidence = tf.split(output_net, [no_objects, no_points * 2, -1], 3)\n",
    "        # print(output_seg.shape)\n",
    "        # print(output_dirs.shape)\n",
    "        # print(confidence.shape)\n",
    "        \n",
    "        # print(no_objects)\n",
    "        coordLSV_in = [output_seg, output_dirs, confidence]\n",
    "        coords = CoordLSVotingWeighted(\n",
    "            name=\"coords_ls_voting\",\n",
    "            num_classes=no_objects,\n",
    "            num_points=no_points,\n",
    "            filter_estimates=True,\n",
    "        )(coordLSV_in)\n",
    "        # print('COORDS_SHAPE')\n",
    "        # print(coords.shape)\n",
    "        poses_est = poses_pnp(\n",
    "            coords, output_seg, keypoints, camera_matrix, no_objects - 1, min_num=opt.min_object_size_test\n",
    "        )\n",
    "        # tf.print(poses_est[0, 0, 0, 0, 0])  # access memory to get sure everything is done\n",
    "\n",
    "        end_time = tf.timestamp()\n",
    "        time_needed = end_time - start_time\n",
    "        return time_needed, poses_est, coords\n",
    "\n",
    "    speed = []\n",
    "    img_batches = []\n",
    "    est_poses = []\n",
    "    coords_list = []\n",
    "    \n",
    "    for batch_idx in tqdm(range(batches)):\n",
    "        img_batch = loader_iterator.get_next()\n",
    "        ### IMAGEONLY\n",
    "        img_batch = tf.expand_dims(img_batch, 0)\n",
    "        img_batch = tuple(img_batch)\n",
    "                \n",
    "        time_needed, poses_est, coords = test_step(img_batch)\n",
    "        speed.append(time_needed)\n",
    "        with open(opt.evalf + \"/speed_eval.csv\", \"a\") as file:\n",
    "            s = \"{},{:.7f}\\n\".format(batch_idx + 1, time_needed)\n",
    "            file.write(s)\n",
    "            \n",
    "        img_batches.append(img_batch)\n",
    "        est_poses.append(poses_est)\n",
    "        coords_list.append(coords)\n",
    "\n",
    "    tf.print(\"average speed: {}\".format(tf.reduce_mean(speed[10:])), summarize=-1)\n",
    "\n",
    "    return loader_iterator, img_batches, est_poses, coords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70cd3c48",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batches: 280.0 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Test Batches: {} \".format(test_batches))\n",
    "\n",
    "testingdata_iterator = iter(testingdata)\n",
    "img_batch = testingdata_iterator.get_next()\n",
    "\n",
    "### IMAGEONLY\n",
    "img_batch = tf.expand_dims(img_batch, 0)\n",
    "img_batch = tuple(img_batch)\n",
    "# keypoints = img_batch[4]\n",
    "# camera_matrix = img_batch[5]\n",
    "\n",
    "type(img_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ba3cfe6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37211ff6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9318e4af",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/280 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\grandid\\miniconda3\\envs\\casapose\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "[TensorShape([8, 9, 2]), TensorShape([8, 9, 3]), TensorShape([3, 3])]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [18:03<00:00,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average speed: 3.8431204945952806\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#testingdata_iterator = iter(testing_images)\n",
    "\n",
    "testingdata_iterator = iter(testingdata)\n",
    "\n",
    "loader_iterator, img_batches, est_poses, coords_list = runnetwork(testingdata_iterator, \n",
    "                                                                  int(test_batches),\n",
    "                                                                  no_objects + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b1fb818",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "274cfadd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from casapose.utils.geometry_utils import apply_offsets, project\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "from casapose.utils.draw_utils import draw_bb, draw_axes\n",
    "import cv2\n",
    "\n",
    "import cv2\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "obj_list = ['obj_000001', \n",
    "            'obj_000005', \n",
    "            'obj_000006', \n",
    "            'obj_000008', \n",
    "            'obj_000009', \n",
    "            'obj_000010', \n",
    "            'obj_000011', \n",
    "            'obj_000016']\n",
    "\n",
    "obj_dict = {\n",
    "\t\"obj_000001\": \"ape\",\n",
    "\t\"obj_000005\": \"wateringcan\",\n",
    "\t\"obj_000006\": \"cat\",\n",
    "\t\"obj_000008\": \"drill\",\n",
    "\t\"obj_000009\": \"duck\",\n",
    "\t\"obj_000010\": \"eggbox\",\n",
    "\t\"obj_000011\": \"glue\",\n",
    "#\t\"obj_000012\": \"holepuncher\", # replaced with headphones\n",
    "\t\"obj_000016\": \"headphones\"\n",
    "}\n",
    "\n",
    "colors = {'blue': (255, 0, 0), 'red': (220,20,60), 'white': (255, 255, 255)}\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 0.6\n",
    "\n",
    "def draw_bb_inference(\n",
    "    img, # [480, 640, 3]\n",
    "    estimated_poses, # [8, 3, 4]\n",
    "    cuboids, # [8, 1, 8, 3]\n",
    "    camera_matrix, # [1, 3, 3]\n",
    "    path,\n",
    "    file_prefix,\n",
    "    gt_pose=None, # [8, 1, 3, 4] or [8, 3, 4] (will be reshaped to latter)\n",
    "    normal=[0.5, 0.5],\n",
    "):\n",
    "        \n",
    "    # image \n",
    "    img_keypoints = tf.cast(((img * normal[1]) + normal[0]) * 255, dtype=tf.uint8).numpy()\n",
    "    img_cuboids = img_keypoints.copy()\n",
    "\n",
    "    eps = 1e-4\n",
    "    \n",
    "    estimated_poses = np.reshape(estimated_poses, (8, 3, 4))\n",
    "    \n",
    "    for obj_idx, obj_pose in enumerate(estimated_poses):\n",
    "        \n",
    "        inst_idx = 0\n",
    "        obj_pose_est = estimated_poses[obj_idx].numpy()\n",
    "        instance_cuboids = cuboids[obj_idx][inst_idx].numpy()\n",
    "        \n",
    "        # draw bb - ESTIMATED\n",
    "        valid_est = np.abs(np.sum(obj_pose_est)) > eps\n",
    "        if valid_est: \n",
    "            #print('est')\n",
    "            #print(obj_pose_est.shape)\n",
    "            transformed_cuboid_points2d, _ = project(instance_cuboids, camera_matrix.numpy(), obj_pose_est)   \n",
    "            transformed_cuboid_points2d = np.reshape(transformed_cuboid_points2d, (8,2))\n",
    "            draw_bb(transformed_cuboid_points2d, img_cuboids, (0, 255, 0))\n",
    "            draw_axes(img=img_cuboids, keypoints=transformed_cuboid_points2d)\n",
    "            \n",
    "        else: \n",
    "            # print(obj_idx)\n",
    "            # print('skipped obj est')\n",
    "            continue\n",
    "\n",
    "        # GT\n",
    "        if gt_pose is not None: \n",
    "            gt_pose = np.reshape(gt_pose, (8, 3, 4))\n",
    "            instance_pose_gt = gt_poses[obj_idx][inst_idx].numpy()\n",
    "            valid_gt = np.abs(np.sum(instance_pose_gt)) > eps\n",
    "            if valid_gt: \n",
    "                gt_pose_est = gt_pose[obj_idx].numpy()\n",
    "                transformed_cuboid_points2d_gt, _ = project(instance_cuboids,camera_matrix.numpy(), gt_pose_est)   \n",
    "                draw_bb(transformed_cuboid_points2d_gt, img_cuboids, (255, 0, 0))\n",
    "                draw_axes(img=img_cuboids, keypoints=transformed_cuboid_points2d)\n",
    "            else: \n",
    "                # print('skipped obj')\n",
    "                continue\n",
    "                \n",
    "                \n",
    "    ### IMAGE LABEL IN CENTER OF CUBE\n",
    "    for obj_idx, obj_pose in enumerate(estimated_poses):\n",
    "        \n",
    "        inst_idx = 0\n",
    "        obj_pose_est = estimated_poses[obj_idx].numpy()\n",
    "        instance_cuboids = cuboids[obj_idx][inst_idx].numpy()\n",
    "        \n",
    "        # draw bb - ESTIMATED\n",
    "        valid_est = np.abs(np.sum(obj_pose_est)) > eps\n",
    "        if valid_est: \n",
    "            transformed_cuboid_points2d, _ = project(instance_cuboids, camera_matrix.numpy(), obj_pose_est)   \n",
    "            transformed_cuboid_points2d = np.reshape(transformed_cuboid_points2d, (8,2))\n",
    "            \n",
    "            text = obj_dict[obj_list[obj_idx]]\n",
    "            thickness = 2\n",
    "            color = colors['white']\n",
    "            center = np.mean(transformed_cuboid_points2d, axis = 0)\n",
    "            center = [int(i) for i in center]\n",
    "            img_test2 = cv2.putText(img_cuboids, \n",
    "                                   text, \n",
    "                                   center, #[50, 100], \n",
    "                                   fontFace = font, \n",
    "                                   fontScale = fontScale, \n",
    "                                   color = color, \n",
    "                                   thickness = thickness)\n",
    "\n",
    "    # save image\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    img_cuboids = Image.fromarray((img_cuboids).astype(\"uint8\"))\n",
    "    img_cuboids.save(path + \"/\" + str(file_prefix) + \"_cuboids_all.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1187996c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9ef19f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddf6d8db",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:34<00:00,  8.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# CAMERA\n",
    "cam_mat = camera_matrix[0]\n",
    "\n",
    "# IMAGE\n",
    "testingdata_iterator = iter(testingdata)\n",
    "\n",
    "\n",
    "for n, img_name in tqdm(enumerate(test_dataset.imgs), total=len(test_dataset.imgs)):\n",
    "    img_batch = testingdata_iterator.get_next()\n",
    "    ### IMAGEONLY\n",
    "    img_batch = tf.expand_dims(img_batch, 0)\n",
    "    img_batch = tuple(img_batch)\n",
    "\n",
    "    img = img_batch[0][0]\n",
    "\n",
    "    # EST POSE\n",
    "    gt_poses = None\n",
    "    poses_est = est_poses[n]\n",
    "    poses_est = np.reshape(poses_est, (1, 8, 3, 4))\n",
    "    estimated_poses=poses_est[0]\n",
    "\n",
    "    file_prefix = img_name.split('\\\\')[-1].split('.')[0]\n",
    "\n",
    "    draw_bb_inference(\n",
    "        img = img, \n",
    "        estimated_poses=estimated_poses,\n",
    "        cuboids=cuboids,\n",
    "        camera_matrix=cam_mat,\n",
    "        path=path_out,\n",
    "        file_prefix=file_prefix,\n",
    "        gt_pose=gt_poses\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41d9a0a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44d01909",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# build the inference video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bd425eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def buildVideo(dataPath):\n",
    "    img_array = []\n",
    "    for filename in tqdm(sorted(glob.glob(dataPath + '/*.png'))):\n",
    "        img = cv2.imread(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "        img_array.append(img)\n",
    "    name = dataPath +f\"/{path_out.split('/')[-1].split('_')[0]}.mp4\"\n",
    "    out = cv2.VideoWriter(name, cv2.VideoWriter_fourcc(*'mp4v'), 30, size)\n",
    "    print(name)\n",
    "    #out = cv2.VideoWriter('inference.mp4', cv2.VideoWriter_fourcc(*'x264'), fps, size)\n",
    "\n",
    "\n",
    "    for i in range(len(img_array)):\n",
    "        out.write(img_array[i])\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9c5a2fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5880e69ca3432f943752c3a6a7bbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/inference5_output/inference5.mp4\n"
     ]
    }
   ],
   "source": [
    "buildVideo(path_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
