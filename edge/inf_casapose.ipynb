{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93f74ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f9d44d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class opt:\n",
    "    modelname = 'casapose_c_gcu5'\n",
    "    estimate_confidence = 1\n",
    "    estimate_coords = 1\n",
    "    confidence_regularization = 1\n",
    "    object = 'obj_000001,obj_000005,obj_000006,obj_000008,obj_000009,obj_000010,obj_000011,obj_000016'\n",
    "\n",
    "    no_points = 9\n",
    "    save_debug_batch = 0\n",
    "\n",
    "    imagesize = (448, 448)\n",
    "    imagesize_test = (480, 640)\n",
    "    crop_factor = 0.933333333\n",
    "    pretrained = 1\n",
    "    manualseed = 1237\n",
    "\n",
    "    # losses\n",
    "    mask_loss_weight = 1.0\n",
    "    vertex_loss_weight = 0.5\n",
    "    proxy_loss_weight = 0.015\n",
    "    keypoint_loss_weight = 0.007\n",
    "    filter_vertex_with_segmentation = 1\n",
    "    filter_high_proxy_errors = 0\n",
    "    use_bpnp_reprojection_loss = 0\n",
    "    max_keypoint_pixel_error = 12.5\n",
    "\n",
    "    # learning rate\n",
    "    lr = 0.001\n",
    "    lr_decay = 0.5\n",
    "    lr_epochs_steps = 50,75,90\n",
    "\n",
    "    # general\n",
    "    gpuids = 0,1\n",
    "    loginterval = 10\n",
    "    epochs = 100\n",
    "    batchsize = 4\n",
    "    saveinterval = 5\n",
    "    validationinterval = 1\n",
    "\n",
    "    # data preprocessing\n",
    "    workers = 0\n",
    "    prefetch = 10\n",
    "\n",
    "    # augmentation\n",
    "    translation = 0\n",
    "    rotation = 0\n",
    "    noise = 0.0001\n",
    "    brightness = 0.001\n",
    "    contrast = 0.001\n",
    "    saturation = 0.001\n",
    "    hue = 0.001\n",
    "    use_imgaug = 1\n",
    "\n",
    "    # test\n",
    "    min_object_size_test = 200\n",
    "    write_poses = 0\n",
    "    save_eval_batches = 0\n",
    "\n",
    "    # output\n",
    "    net = 'training_checkpoints'\n",
    "    outf = 'train_casapose_8_16_objects'\n",
    "\n",
    "    # config\n",
    "    train_vectors_with_ground_truth = 1\n",
    "    load_h5_weights = 0\n",
    "    copy_weights_from_backup_network = 0\n",
    "    copy_weights_add_confidence_maps = 0\n",
    "    objects_in_input_network = 8\n",
    "    objects_to_copy = 1\n",
    "    objects_to_copy_list = 'config/objects_to_copy.csv'\n",
    "    \n",
    "    confidence_filter_estimates = 1\n",
    "    confidence_choose_second = 0\n",
    "    train_vectors_with_ground_truth = 0\n",
    "    datatest_wxyz_quaterion = 0\n",
    "    filter_test_with_gt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e04e9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/imgaug/imgaug.py:184: DeprecationWarning: Function `ContrastNormalization()` is deprecated. Use `imgaug.contrast.LinearContrast` instead.\n",
      "  warn_deprecated(msg, stacklevel=3)\n",
      "/usr/local/lib/python3.8/dist-packages/imgaug/imgaug.py:184: DeprecationWarning: Function `FrequencyNoiseAlpha()` is deprecated. Use `BlendAlphaFrequencyNoise` instead. FrequencyNoiseAlpha is deprecated. Use BlendAlphaFrequencyNoise instead. The order of parameters is the same. Parameter 'first' was renamed to 'foreground'. Parameter 'second' was renamed to 'background'.\n",
      "  warn_deprecated(msg, stacklevel=3)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CASAPOSE_INFERENCE\"] = \"True\"\n",
    "\n",
    "from casapose.data_handler.vectorfield_dataset import VectorfieldDataset\n",
    "from casapose.data_handler.image_only_dataset import ImageOnlyDataset\n",
    "from casapose.pose_estimation.pose_evaluation import (\n",
    "    estimate_and_evaluate_poses,\n",
    "    evaluate_pose_estimates,\n",
    ")\n",
    "from casapose.pose_estimation.voting_layers_2d import CoordLSVotingWeighted\n",
    "from casapose.pose_models.tfkeras import Classifiers\n",
    "from casapose.utils.config_parser import parse_config\n",
    "#from casapose.utils.dataset_utils import save_eval_batch  # , save_eval_comparison\n",
    "from casapose.utils.inf_dataset_utils import save_eval_batch  # , save_eval_comparison\n",
    "from casapose.utils.image_utils import get_all_vectorfields\n",
    "# from casapose.utils.io_utils import write_poses\n",
    "from casapose.utils.loss_functions import (\n",
    "    keypoint_reprojection_loss,\n",
    "    proxy_voting_dist,\n",
    "    proxy_voting_loss_v2,\n",
    "    smooth_l1_loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "952a3039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 11:06:21.877963: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 11:06:21.967468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 11:06:22.003550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 11:06:22.005242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 11:06:22.367768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 11:06:22.368757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 11:06:22.369517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 11:06:22.370218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20397 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea8b39a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(\n",
    "    output_seg,\n",
    "    target_seg,\n",
    "    output_vertex,\n",
    "    target_vertex,\n",
    "    target_points,\n",
    "    mask_loss_weight=1.0,\n",
    "    vertex_loss_weight=1.0,\n",
    "    proxy_loss_weight=1.0,\n",
    "    kp_loss_weight=0.0,\n",
    "    kp_loss=None,\n",
    "):\n",
    "\n",
    "    oc = np.int32(target_seg.shape[3] - 1)  # object count\n",
    "    vc = target_points.shape[3] * 2  # vertex count\n",
    "    kp_loss = tf.constant(0.0, dtype=tf.float32)\n",
    "    mask_loss = tf.reduce_mean(\n",
    "        input_tensor=tf.nn.softmax_cross_entropy_with_logits(labels=target_seg, logits=output_seg)\n",
    "    )\n",
    "    separated_vectors = oc > 1 and output_vertex.shape[-1] == (oc * vc)  # original pvnet with multiple objects\n",
    "\n",
    "    if kp_loss is None:\n",
    "        kp_loss = tf.constant(0.0, dtype=tf.float32)\n",
    "\n",
    "    if separated_vectors:  #\n",
    "        vertex_loss = sum(\n",
    "            smooth_l1_loss(\n",
    "                output_vertex[:, :, :, i * vc : (i + 1) * vc],\n",
    "                target_vertex[:, :, :, i * vc : (i + 1) * vc],\n",
    "                target_seg[:, :, :, i + 1 : i + 2],\n",
    "            )\n",
    "            for i in range(oc)\n",
    "        )\n",
    "        proxy_loss = sum(\n",
    "            proxy_voting_loss_v2(\n",
    "                output_vertex[:, :, :, i * vc : (i + 1) * vc],\n",
    "                target_points[:, i : i + 1, :, :, :],\n",
    "                vertex_one_hot_weights=target_seg[:, :, :, i + 1 : i + 2],\n",
    "                vertex_weights=target_seg[:, :, :, i + 1 : i + 2],\n",
    "            )\n",
    "            for i in range(oc)\n",
    "        )\n",
    "    else:\n",
    "        vertex_loss = smooth_l1_loss(\n",
    "            output_vertex,\n",
    "            target_vertex,\n",
    "            target_seg[:, :, :, 0:1],\n",
    "            invert_weights=True,\n",
    "        )\n",
    "        proxy_loss = proxy_voting_loss_v2(\n",
    "            output_vertex,\n",
    "            target_points,\n",
    "            vertex_one_hot_weights=target_seg[:, :, :, 1:],\n",
    "            vertex_weights=target_seg[:, :, :, 0:1],\n",
    "            invert_weights=True,\n",
    "            loss_per_object=False,\n",
    "        )\n",
    "\n",
    "    loss = (\n",
    "        tf.multiply(mask_loss, mask_loss_weight)\n",
    "        + tf.multiply(proxy_loss, proxy_loss_weight)\n",
    "        + tf.multiply(vertex_loss, vertex_loss_weight)\n",
    "        + tf.multiply(kp_loss, kp_loss_weight)\n",
    "    )\n",
    "    return [loss, mask_loss, vertex_loss, proxy_loss, kp_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31563d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = parse_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5091ed99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 11:06:22.405416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 11:06:22.406288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 11:06:22.407013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 11:06:22.407905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 11:06:22.408611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 11:06:22.409320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 11:06:22.410057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 11:06:22.410750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 11:06:22.411387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20397 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/gpu:0']\n",
      "[<KerasTensor: shape=(None, 240, 320, 64) dtype=float32 (created by layer 'relu0')>, <KerasTensor: shape=(None, 120, 160, 64) dtype=float32 (created by layer 'stage2_unit1_relu1')>, <KerasTensor: shape=(None, 60, 80, 128) dtype=float32 (created by layer 'stage3_unit1_relu1')>, <KerasTensor: shape=(None, 60, 80, 256) dtype=float32 (created by layer 'stage4_unit1_relu1')>, <KerasTensor: shape=(None, 60, 80, 512) dtype=float32 (created by layer 'relu1')>]\n"
     ]
    }
   ],
   "source": [
    "# if not os.path.exists(opt.evalf):\n",
    "#     os.makedirs(opt.evalf)\n",
    "\n",
    "# checkpoint_path = opt.outf + \"/\" + opt.net\n",
    "\n",
    "# frozen_path = opt.outf + \"/frozen_model\"\n",
    "# img_out_path = opt.outf + \"/control_output\"\n",
    "\n",
    "\n",
    "# def create_dir(path):\n",
    "#     try:\n",
    "#         os.makedirs(path)\n",
    "#     except OSError:\n",
    "#         pass\n",
    "\n",
    "\n",
    "# create_dir(img_out_path)\n",
    "# create_dir(frozen_path)\n",
    "\n",
    "# save the hyper parameters passed\n",
    "# with open(opt.evalf + \"/header_eval.txt\", \"w\") as file:\n",
    "#     file.write(str(opt))\n",
    "\n",
    "# set the manual seed.\n",
    "# np.random.seed(opt.manualseed)\n",
    "# tf.random.set_seed(opt.manualseed)\n",
    "\n",
    "test_dataset = None\n",
    "\n",
    "device_ids = []\n",
    "if len(opt.gpuids) == 1 and opt.gpuids[0] < 0:\n",
    "    device_ids.append(\"/cpu:0\")\n",
    "else:\n",
    "    device_ids.append(\"/gpu:{}\".format(opt.gpuids[0]))\n",
    "print(device_ids)\n",
    "\n",
    "objectsofinterest = [x.strip() for x in opt.object.split(\",\")]\n",
    "no_objects = len(objectsofinterest)\n",
    "separated_vectorfields = opt.modelname == \"pvnet\"\n",
    "\n",
    "testingdata = None\n",
    "normal_imgs = [0.5, 0.5]\n",
    "\n",
    "use_split = False\n",
    "# if opt.data == opt.datatest:\n",
    "#     print(\"split datasets with ratio {}\".format(opt.train_validation_split))\n",
    "#     use_split = True\n",
    "\n",
    "test_batches = 0\n",
    "\n",
    "\n",
    "#print(\"testing data: {} batches\".format(test_batches))\n",
    "\n",
    "# if opt.backbonename != \"resnet18\":\n",
    "#     print(opt.backbonename + \" is not a supported backbone.\")\n",
    "#     exit()\n",
    "\n",
    "\n",
    "input_segmentation_shape = None\n",
    "# if opt.train_vectors_with_ground_truth is True:\n",
    "#     input_segmentation_shape = (\n",
    "#         opt.imagesize_test[0],\n",
    "#         opt.imagesize_test[1],\n",
    "#         1 + no_objects,\n",
    "#     )\n",
    "\n",
    "\n",
    "height = 480 #Taken from config_8.ini\n",
    "width = 640 # Taken from config_8.ini\n",
    "\n",
    "CASAPose = Classifiers.get(opt.modelname)\n",
    "ver_dim = 9 * 2 # Taken from config_8.ini\n",
    "if opt.modelname == \"pvnet\":\n",
    "    ver_dim = ver_dim * no_objects\n",
    "\n",
    "if opt.estimate_confidence:\n",
    "    assert separated_vectorfields is not None, \"confidence not compatitble with this model\"\n",
    "    ver_dim += 9 # Taken from config_8.ini\n",
    "\n",
    "net = CASAPose(\n",
    "    ver_dim=ver_dim,\n",
    "    seg_dim=1 + no_objects,\n",
    "    input_shape=(height, width, 3),\n",
    "    input_segmentation_shape=input_segmentation_shape,\n",
    "    weights=\"imagenet\",\n",
    "    base_model=\"resnet18\", # Hardcoded param\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92cb5a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_prefix = os.path.join(checkpoint_path, \"ckpt\")\n",
    "# checkpoint = tf.train.Checkpoint(network=net)  # , optimizer=optimizer)\n",
    "\n",
    "\n",
    "net_path = \"/workspace/CASAPose/data/pretrained_models/result_w.h5\" # CHANGE TO .H5 FILEPATH\n",
    "net.load_weights(net_path, by_name=True, skip_mismatch=True)\n",
    "\n",
    "\n",
    "# elif opt.net != \"\":\n",
    "#     checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path)).expect_partial()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d13a8c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " data (InputLayer)              [(None, 480, 640, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model (Functional)             [(None, 240, 320, 6  11186889    ['data[0][0]']                   \n",
      "                                4),                                                               \n",
      "                                 (None, 120, 160, 6                                               \n",
      "                                4),                                                               \n",
      "                                 (None, 60, 80, 128                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 60, 80, 256                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 60, 80, 512                                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_18 (ZeroPadding  (None, 62, 82, 512)  0          ['model[0][4]']                  \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " pv_block_1_conv2d (Conv2D)     (None, 60, 80, 256)  1179648     ['zero_padding2d_18[0][0]']      \n",
      "                                                                                                  \n",
      " pv_block_1_bn (SyncBatchNormal  (None, 60, 80, 256)  1024       ['pv_block_1_conv2d[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " pv_block_1_relu (Activation)   (None, 60, 80, 256)  0           ['pv_block_1_bn[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 60, 80, 384)  0           ['pv_block_1_relu[0][0]',        \n",
      "                                                                  'model[0][2]']                  \n",
      "                                                                                                  \n",
      " zero_padding2d_19 (ZeroPadding  (None, 62, 82, 384)  0          ['concatenate[0][0]']            \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " pv_block_2_conv2d (Conv2D)     (None, 60, 80, 128)  442368      ['zero_padding2d_19[0][0]']      \n",
      "                                                                                                  \n",
      " pv_block_2_bn (SyncBatchNormal  (None, 60, 80, 128)  512        ['pv_block_2_conv2d[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 60, 80, 128)  0           ['pv_block_2_bn[0][0]']          \n",
      "                                                                                                  \n",
      " pv_block_2_relu1 (Activation)  (None, 60, 80, 128)  0           ['pv_block_2_bn[0][0]']          \n",
      "                                                                                                  \n",
      " pv_block_2_relu2 (Activation)  (None, 60, 80, 128)  0           ['tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      " subtract (Subtract)            (None, 60, 80, 128)  0           ['pv_block_2_relu1[0][0]',       \n",
      "                                                                  'pv_block_2_relu2[0][0]']       \n",
      "                                                                                                  \n",
      " pv_block_2_upsampling (UpSampl  (None, 120, 160, 12  0          ['subtract[0][0]']               \n",
      " ing2D)                         8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 120, 160, 19  0           ['pv_block_2_upsampling[0][0]',  \n",
      "                                2)                                'model[0][1]']                  \n",
      "                                                                                                  \n",
      " zero_padding2d_20 (ZeroPadding  (None, 122, 162, 19  0          ['concatenate_1[0][0]']          \n",
      " 2D)                            2)                                                                \n",
      "                                                                                                  \n",
      " pv_block_3_conv2d (Conv2D)     (None, 120, 160, 64  110592      ['zero_padding2d_20[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_3_bn (SyncBatchNormal  (None, 120, 160, 64  256        ['pv_block_3_conv2d[0][0]']      \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 120, 160, 64  0          ['pv_block_3_bn[0][0]']          \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_3_relu1 (Activation)  (None, 120, 160, 64  0           ['pv_block_3_bn[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_3_relu2 (Activation)  (None, 120, 160, 64  0           ['tf.math.multiply_1[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " subtract_1 (Subtract)          (None, 120, 160, 64  0           ['pv_block_3_relu1[0][0]',       \n",
      "                                )                                 'pv_block_3_relu2[0][0]']       \n",
      "                                                                                                  \n",
      " pv_block_3_upsampling (UpSampl  (None, 240, 320, 64  0          ['subtract_1[0][0]']             \n",
      " ing2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 240, 320, 12  0           ['pv_block_3_upsampling[0][0]',  \n",
      "                                8)                                'model[0][0]']                  \n",
      "                                                                                                  \n",
      " zero_padding2d_21 (ZeroPadding  (None, 242, 322, 12  0          ['concatenate_2[0][0]']          \n",
      " 2D)                            8)                                                                \n",
      "                                                                                                  \n",
      " pv_block_4_conv2d (Conv2D)     (None, 240, 320, 32  36864       ['zero_padding2d_21[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_4_bn (SyncBatchNormal  (None, 240, 320, 32  128        ['pv_block_4_conv2d[0][0]']      \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, 240, 320, 32  0          ['pv_block_4_bn[0][0]']          \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_4_relu1 (Activation)  (None, 240, 320, 32  0           ['pv_block_4_bn[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_4_relu2 (Activation)  (None, 240, 320, 32  0           ['tf.math.multiply_2[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " subtract_2 (Subtract)          (None, 240, 320, 32  0           ['pv_block_4_relu1[0][0]',       \n",
      "                                )                                 'pv_block_4_relu2[0][0]']       \n",
      "                                                                                                  \n",
      " pv_block_4_upsampling (UpSampl  (None, 480, 640, 32  0          ['subtract_2[0][0]']             \n",
      " ing2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 480, 640, 35  0           ['pv_block_4_upsampling[0][0]',  \n",
      "                                )                                 'data[0][0]']                   \n",
      "                                                                                                  \n",
      " zero_padding2d_22 (ZeroPadding  (None, 482, 642, 35  0          ['concatenate_3[0][0]']          \n",
      " 2D)                            )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_5_conv2d (Conv2D)     (None, 480, 640, 32  10080       ['zero_padding2d_22[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_5_bn (SyncBatchNormal  (None, 480, 640, 32  128        ['pv_block_5_conv2d[0][0]']      \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, 480, 640, 32  0          ['pv_block_5_bn[0][0]']          \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_5_relu1 (Activation)  (None, 480, 640, 32  0           ['pv_block_5_bn[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_5_relu2 (Activation)  (None, 480, 640, 32  0           ['tf.math.multiply_3[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " subtract_3 (Subtract)          (None, 480, 640, 32  0           ['pv_block_5_relu1[0][0]',       \n",
      "                                )                                 'pv_block_5_relu2[0][0]']       \n",
      "                                                                                                  \n",
      " pv_final_conv_segmentation (Co  (None, 480, 640, 9)  288        ['subtract_3[0][0]']             \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None, 480, 640, 9)  0          ['pv_final_conv_segmentation[0][0\n",
      " )                                                               ]']                              \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 480, 640, 9)  0           ['tf.math.multiply_4[0][0]']     \n",
      "                                                                                                  \n",
      " tf.stop_gradient (TFOpLambda)  (None, 480, 640, 9)  0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " segmentation_half_size (HalfSi  (None, 240, 320, 9)  0          ['tf.stop_gradient[0][0]']       \n",
      " ze)                                                                                              \n",
      "                                                                                                  \n",
      " segmentation_quater_size (Half  (None, 120, 160, 9)  0          ['segmentation_half_size[0][0]'] \n",
      " Size)                                                                                            \n",
      "                                                                                                  \n",
      " segmentation_eighth_size (Half  (None, 60, 80, 9)   0           ['segmentation_quater_size[0][0]'\n",
      " Size)                                                           ]                                \n",
      "                                                                                                  \n",
      " pv_block_6_prepare_conv2d (Par  (None, 60, 80, 256)  1179648    ['model[0][4]',                  \n",
      " tialConvolution)                                                 'segmentation_eighth_size[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " pv_block_6_clade (ClassAdaptiv  (None, 60, 80, 256)  5120       ['pv_block_6_prepare_conv2d[0][0]\n",
      " eWeightedNormalization)                                         ',                               \n",
      "                                                                  'segmentation_eighth_size[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " pv_block_6_relu (Activation)   (None, 60, 80, 256)  0           ['pv_block_6_clade[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 60, 80, 384)  0           ['pv_block_6_relu[0][0]',        \n",
      "                                                                  'model[0][2]']                  \n",
      "                                                                                                  \n",
      " pv_block_7_prepare_conv2d (Par  (None, 60, 80, 128)  442368     ['concatenate_4[0][0]',          \n",
      " tialConvolution)                                                 'segmentation_eighth_size[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " pv_block_7_clade (ClassAdaptiv  (None, 60, 80, 128)  2560       ['pv_block_7_prepare_conv2d[0][0]\n",
      " eWeightedNormalization)                                         ',                               \n",
      "                                                                  'segmentation_eighth_size[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None, 60, 80, 128)  0          ['pv_block_7_clade[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pv_block_7_relu1 (Activation)  (None, 60, 80, 128)  0           ['pv_block_7_clade[0][0]']       \n",
      "                                                                                                  \n",
      " pv_block_7_relu2 (Activation)  (None, 60, 80, 128)  0           ['tf.math.multiply_5[0][0]']     \n",
      "                                                                                                  \n",
      " subtract_4 (Subtract)          (None, 60, 80, 128)  0           ['pv_block_7_relu1[0][0]',       \n",
      "                                                                  'pv_block_7_relu2[0][0]']       \n",
      "                                                                                                  \n",
      " pv_block_7_guided_upsamling (G  (None, 120, 160, 12  0          ['subtract_4[0][0]',             \n",
      " uidedUpsampling)               8)                                'segmentation_eighth_size[0][0]'\n",
      "                                                                 , 'segmentation_quater_size[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 120, 160, 19  0           ['pv_block_7_guided_upsamling[0][\n",
      "                                2)                               0]',                             \n",
      "                                                                  'model[0][1]']                  \n",
      "                                                                                                  \n",
      " pv_block_8_prepare_conv2d (Par  (None, 120, 160, 64  110592     ['concatenate_5[0][0]',          \n",
      " tialConvolution)               )                                 'segmentation_quater_size[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " pv_block_8_clade (ClassAdaptiv  (None, 120, 160, 64  1280       ['pv_block_8_prepare_conv2d[0][0]\n",
      " eWeightedNormalization)        )                                ',                               \n",
      "                                                                  'segmentation_quater_size[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None, 120, 160, 64  0          ['pv_block_8_clade[0][0]']       \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_8_relu1 (Activation)  (None, 120, 160, 64  0           ['pv_block_8_clade[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_8_relu2 (Activation)  (None, 120, 160, 64  0           ['tf.math.multiply_6[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " subtract_5 (Subtract)          (None, 120, 160, 64  0           ['pv_block_8_relu1[0][0]',       \n",
      "                                )                                 'pv_block_8_relu2[0][0]']       \n",
      "                                                                                                  \n",
      " pv_block_8_guided_upsamling (G  (None, 240, 320, 64  0          ['subtract_5[0][0]',             \n",
      " uidedUpsampling)               )                                 'segmentation_quater_size[0][0]'\n",
      "                                                                 , 'segmentation_half_size[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 240, 320, 12  0           ['pv_block_8_guided_upsamling[0][\n",
      "                                8)                               0]',                             \n",
      "                                                                  'model[0][0]']                  \n",
      "                                                                                                  \n",
      " pv_block_9_prepare_conv2d (Par  (None, 240, 320, 32  36864      ['concatenate_6[0][0]',          \n",
      " tialConvolution)               )                                 'segmentation_half_size[0][0]'] \n",
      "                                                                                                  \n",
      " pv_block_9_clade (ClassAdaptiv  (None, 240, 320, 32  640        ['pv_block_9_prepare_conv2d[0][0]\n",
      " eWeightedNormalization)        )                                ',                               \n",
      "                                                                  'segmentation_half_size[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLambda  (None, 240, 320, 32  0          ['pv_block_9_clade[0][0]']       \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_9_relu1 (Activation)  (None, 240, 320, 32  0           ['pv_block_9_clade[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_9_relu2 (Activation)  (None, 240, 320, 32  0           ['tf.math.multiply_7[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " subtract_6 (Subtract)          (None, 240, 320, 32  0           ['pv_block_9_relu1[0][0]',       \n",
      "                                )                                 'pv_block_9_relu2[0][0]']       \n",
      "                                                                                                  \n",
      " pv_block_9_guided_upsamling (G  (None, 480, 640, 32  0          ['subtract_6[0][0]',             \n",
      " uidedUpsampling)               )                                 'segmentation_half_size[0][0]', \n",
      "                                                                  'tf.stop_gradient[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 480, 640, 35  0           ['pv_block_9_guided_upsamling[0][\n",
      "                                )                                0]',                             \n",
      "                                                                  'data[0][0]']                   \n",
      "                                                                                                  \n",
      " pv_block_10_prepare_conv2d (Pa  (None, 480, 640, 32  10080      ['concatenate_7[0][0]',          \n",
      " rtialConvolution)              )                                 'tf.stop_gradient[0][0]']       \n",
      "                                                                                                  \n",
      " pv_block_10_clade (ClassAdapti  (None, 480, 640, 32  640        ['pv_block_10_prepare_conv2d[0][0\n",
      " veWeightedNormalization)       )                                ]',                              \n",
      "                                                                  'tf.stop_gradient[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLambda  (None, 480, 640, 32  0          ['pv_block_10_clade[0][0]']      \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_10_relu1 (Activation)  (None, 480, 640, 32  0          ['pv_block_10_clade[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_block_10_relu2 (Activation)  (None, 480, 640, 32  0          ['tf.math.multiply_8[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " subtract_7 (Subtract)          (None, 480, 640, 32  0           ['pv_block_10_relu1[0][0]',      \n",
      "                                )                                 'pv_block_10_relu2[0][0]']      \n",
      "                                                                                                  \n",
      " pv_final_conv_vertex (Conv2D)  (None, 480, 640, 27  864         ['subtract_7[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pv_final_concatenation (Concat  (None, 480, 640, 36  0          ['pv_final_conv_segmentation[0][0\n",
      " enate)                         )                                ]',                              \n",
      "                                                                  'pv_final_conv_vertex[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,759,433\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,759,433\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in net.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "net.summary()\n",
    "\n",
    "# if os.path.exists(opt.evalf + \"/poses_out/\"):\n",
    "#     files = sorted(glob.glob(opt.evalf + \"/poses_out/*/\" + \"*.txt\"))\n",
    "#     for f in files:\n",
    "#         os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cd590b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runnetwork(loader_iterator, batches):\n",
    "    # @tf.function\n",
    "    # def tf_test_step(img_batch):\n",
    "    #    return test_step(img_batch)\n",
    "\n",
    "    # @tf.function\n",
    "    # def test_step(img_batch):\n",
    "    for batch_idx in range(batches):\n",
    "\n",
    "        img_batch = loader_iterator.get_next()\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        target_seg = img_batch[1]\n",
    "        target_vertex = img_batch[3]\n",
    "        keypoints = img_batch[4]\n",
    "        cam_mat = img_batch[5]\n",
    "        diameters = img_batch[6]\n",
    "        offsets = img_batch[7]\n",
    "        filtered_seg = img_batch[8]\n",
    "        poses_gt = img_batch[10]\n",
    "        confidence = None\n",
    "        kp_loss = None\n",
    "        no_features = target_vertex.shape[3]  # vertex count\n",
    "        no_points = opt.no_points\n",
    "        no_objects = target_seg.shape[3]\n",
    "\n",
    "        separated_vectorfields = opt.modelname == \"pvnet\"\n",
    "\n",
    "        target_dirs = get_all_vectorfields(\n",
    "            target_seg,\n",
    "            target_vertex,\n",
    "            filtered_seg,\n",
    "            separated_vectorfields,\n",
    "        )\n",
    "\n",
    "        net_input = [img_batch[0]]\n",
    "        # if opt.train_vectors_with_ground_truth:\n",
    "        #     net_input.append(target_seg)\n",
    "\n",
    "        # start_time = tf.timestamp()\n",
    "        output_net = net(net_input, training=False)  # all stages are present here\n",
    "\n",
    "        if opt.estimate_confidence:\n",
    "            output_seg, output_dirs, confidence = tf.split(output_net, [no_objects, no_points * 2, -1], 3)\n",
    "        else:\n",
    "            output_seg, output_dirs = tf.split(output_net, [no_objects, -1], 3)\n",
    "\n",
    "        if opt.estimate_coords:\n",
    "            if opt.train_vectors_with_ground_truth:\n",
    "                coordLSV_in = [target_seg, output_dirs, confidence]\n",
    "            else:\n",
    "                coordLSV_in = [output_seg, output_dirs, confidence]\n",
    "\n",
    "            coords = CoordLSVotingWeighted(\n",
    "                name=\"coords_ls_voting\",\n",
    "                num_classes=no_objects,\n",
    "                num_points=no_points,\n",
    "                filter_estimates=opt.confidence_filter_estimates,\n",
    "                output_second_largest_component=opt.confidence_choose_second,\n",
    "            )(coordLSV_in)\n",
    "\n",
    "            kp_loss, poses_est, points_est = keypoint_reprojection_loss(\n",
    "                coords,\n",
    "                output_seg,\n",
    "                poses_gt,\n",
    "                keypoints,\n",
    "                target_seg,\n",
    "                cam_mat,\n",
    "                offsets,\n",
    "                confidence,\n",
    "                min_num=opt.min_object_size_test,\n",
    "                min_num_gt=1,\n",
    "                use_bpnp_reprojection_loss=opt.use_bpnp_reprojection_loss,\n",
    "                estimate_poses=True,\n",
    "                filter_with_gt=opt.filter_test_with_gt,\n",
    "            )\n",
    "\n",
    "        if opt.estimate_coords:\n",
    "            pose_stats, estimated_poses, estimated_points = evaluate_pose_estimates(\n",
    "                points_est,\n",
    "                poses_est,\n",
    "                poses_gt,\n",
    "                target_seg,\n",
    "                keypoints,\n",
    "                cam_mat,\n",
    "                diameters,\n",
    "                evaluation_points=mesh_vertex_array,\n",
    "                object_points_3d_count=mesh_vertex_count,\n",
    "                min_num=1,\n",
    "            )\n",
    "            estimated_poses = tf.squeeze(estimated_poses, axis=2)\n",
    "        else:\n",
    "            pose_stats, estimated_poses, estimated_points = estimate_and_evaluate_poses(\n",
    "                output_seg,\n",
    "                target_seg,\n",
    "                output_dirs,\n",
    "                poses_gt,\n",
    "                keypoints,\n",
    "                cam_mat,\n",
    "                diameters,\n",
    "                offsets,\n",
    "                evaluation_points=mesh_vertex_array,\n",
    "                object_points_3d_count=mesh_vertex_count,\n",
    "                min_num=1,\n",
    "            )\n",
    "\n",
    "        # end_time = tf.timestamp()\n",
    "        # time_needed = end_time - start_time\n",
    "\n",
    "        loss = compute_loss(\n",
    "            output_seg,\n",
    "            target_seg,\n",
    "            output_dirs,\n",
    "            target_dirs,\n",
    "            target_vertex,\n",
    "            opt.mask_loss_weight,\n",
    "            opt.vertex_loss_weight,\n",
    "            opt.proxy_loss_weight,\n",
    "            opt.keypoint_loss_weight,\n",
    "            kp_loss=kp_loss,\n",
    "        )\n",
    "        loss.append(pose_stats)\n",
    "\n",
    "        _, object_loss_values = proxy_voting_dist(\n",
    "            output_dirs,\n",
    "            target_vertex,\n",
    "            vertex_one_hot_weights=target_seg[:, :, :, 1:],\n",
    "            vertex_weights=target_seg[:, :, :, 0:1],\n",
    "            invert_weights=True,\n",
    "        )\n",
    "        loss.append(object_loss_values)\n",
    "        # loss.append(time_needed)\n",
    "\n",
    "        # if opt.write_poses:\n",
    "        #     write_poses(\n",
    "        #         tf.squeeze(poses_gt, 0),\n",
    "        #         tf.squeeze(estimated_poses, 0),\n",
    "        #         objectsofinterest,\n",
    "        #         img_batch[12],\n",
    "        #         opt.evalf + \"/poses_out/\",\n",
    "        #     )\n",
    "\n",
    "        # if opt.save_eval_batches:\n",
    "\n",
    "        beta = tf.cast(1e6, dtype=output_seg.dtype)\n",
    "        hot_seg = tf.expand_dims(tf.expand_dims(tf.nn.softmax(output_seg * beta), -1), -1)[:, :, :, 1:, :, :]\n",
    "        w = tf.math.softplus(confidence)\n",
    "        hot_seg_ = tf.squeeze(hot_seg, axis=-1)\n",
    "        w_ = hot_seg_ * tf.expand_dims(w, axis=-2)\n",
    "        w_max = tf.reduce_max(w_, axis=[0, 1, 2], keepdims=True)\n",
    "        w_min = tf.reduce_min(w_, axis=[0, 1, 2], keepdims=True)\n",
    "        w_ = tf.math.divide_no_nan(tf.subtract(w_, w_min), tf.subtract(w_max, w_min))\n",
    "        confidence = tf.reduce_sum(w_, axis=-2)\n",
    "\n",
    "        add_correct = loss[5][1]\n",
    "\n",
    "        image = save_eval_batch(\n",
    "                img_batch,\n",
    "                output_seg,\n",
    "                target_dirs,\n",
    "                output_dirs,\n",
    "                estimated_poses,\n",
    "                estimated_points,\n",
    "                no_objects - 1,\n",
    "                no_features,\n",
    "                # path_out=opt.evalf + \"/visual_batch_eval_mask\",\n",
    "                confidence=confidence,\n",
    "                add_correct=add_correct,\n",
    "                )\n",
    "            \n",
    "        tf.print(\"Estimated Coordinates: {}\".format(estimated_points), summarize=-1)\n",
    "        tf.print(\"Estimated Poses: {}\".format(estimated_poses), summarize=-1)\n",
    "        tf.print(\"Segmentation Masks: {}\".format(output_seg), summarize=-1)\n",
    "        tf.print(\"Image: {}\".format(type(image)), summarize=-1)\n",
    "        #tf.print(\"Labels: TESTING\") #{}\".format(test_pose_count_gt), summarize=-1)\n",
    "        tf.print(\"Objects of Interest: {}\".format(objectsofinterest), summarize=-1)\n",
    "        tf.print(\"length: {}\".format(len(objectsofinterest)), summarize=-1)\n",
    "        tf.print(\"Number of Objects: {}\".format(no_objects), summarize=-1)\n",
    "        \n",
    "\n",
    "        return image\n",
    "        # return loss, estimated_points, estimated_poses, output_seg\n",
    "        # return estimated_points, estimated_poses, output_seg\n",
    "\n",
    "        # def test_pose_step(dataset_inputs):\n",
    "            # if opt.save_eval_batches or opt.write_poses:\n",
    "                # loss, \n",
    "            # estimated_points, estimated_poses, output_seg = test_step(dataset_inputs)\n",
    "            # else:\n",
    "                # loss, estimated_points, estimated_poses, output_seg = tf_test_step(dataset_inputs)\n",
    "\n",
    "            # return [\n",
    "            #     loss[0],\n",
    "            #     loss[1],\n",
    "            #     loss[2],\n",
    "            #     loss[3],\n",
    "            #     loss[4],\n",
    "            #     loss[5][0],\n",
    "            #     loss[5][1],\n",
    "            #     loss[5][2],\n",
    "            #     loss[5][3],\n",
    "            #     loss[5][4],\n",
    "            #     loss[5][5],\n",
    "            #     loss[5][6],\n",
    "            #     loss[5][7],\n",
    "            #     loss[6],\n",
    "            #     loss[7],\n",
    "            # ], return estimated_points, estimated_poses, output_seg\n",
    "\n",
    "    # test_loss = tf.zeros([5], dtype=tf.float32)\n",
    "    # test_pose_2d_count = tf.zeros([no_objects], dtype=tf.float32)\n",
    "    # test_pose_3d_count = tf.zeros([no_objects], dtype=tf.float32)\n",
    "    # test_pose_count_gt = tf.zeros([no_objects], dtype=tf.float32)\n",
    "    # test_pose_count_fp = tf.zeros([no_objects], dtype=tf.float32)\n",
    "    # test_pose_err_2d = tf.zeros([no_objects], dtype=tf.float32)\n",
    "    # test_pose_err_3d = tf.zeros([no_objects], dtype=tf.float32)\n",
    "    # missed_object_count = tf.zeros([no_objects], dtype=tf.float32)\n",
    "\n",
    "    # for batch_idx in range(batches):\n",
    "\n",
    "        # img_batch = loader_iterator.get_next()\n",
    "        # loss, \n",
    "        # image, estimated_points, estimated_poses, output_seg = test_step(img_batch)\n",
    "        # estimated_points, estimated_poses, output_seg = test_pose_step(img_batch)\n",
    "        # test_pose_2d_count += loss[5]\n",
    "        # test_pose_3d_count += loss[6]\n",
    "        # test_pose_count_gt += loss[7]\n",
    "        # test_pose_count_fp += loss[12]\n",
    "        # test_pose_err_2d += loss[9]\n",
    "        # test_pose_err_3d += loss[10]\n",
    "        # missed_object_count += loss[11]\n",
    "        # test_loss += loss[0:5]\n",
    "        \n",
    "        # tf.print(\"Estimated Coordinates: {}\".format(estimated_points), summarize=-1)\n",
    "        # tf.print(\"Estimated Poses: {}\".format(estimated_poses), summarize=-1)\n",
    "        # tf.print(\"Segmentation Masks: {}\".format(output_seg), summarize=-1)\n",
    "        # tf.print(\"Image: {}\".format(type(image)), summarize=-1)\n",
    "        # tf.print(\"Labels: TESTING\") #{}\".format(test_pose_count_gt), summarize=-1)\n",
    "\n",
    "    # test_loss /= batches\n",
    "\n",
    "    # err_2d = tf.math.divide_no_nan(test_pose_2d_count, test_pose_count_gt)\n",
    "    # err_3d = tf.math.divide_no_nan(test_pose_3d_count, test_pose_count_gt)\n",
    "    # detection_count = test_pose_count_gt - missed_object_count + test_pose_count_fp\n",
    "    # detection_count = tf.where(test_pose_count_gt == 0.0, 0.0, detection_count)\n",
    "    # precision = tf.math.divide_no_nan(test_pose_3d_count, detection_count)\n",
    "\n",
    "    # return loader_iterator, image, estimated_points, estimated_poses, output_seg\n",
    "\n",
    "\n",
    "# cap = cv2.VideoCapture('drive/MyDrive/MIDS/w251/final_project/desk.mp4')\n",
    "\n",
    "#img = cv2.imread(\"color.png\")\n",
    "#test_dataset = ImageOnlyDataset(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d04626c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/CASAPose/import_data/test/models/obj_000001/obj_000001.ply\n",
      "/workspace/CASAPose/import_data/test/models/obj_000002/obj_000002.ply\n",
      "/workspace/CASAPose/import_data/test/models/obj_000003/obj_000003.ply\n",
      "/workspace/CASAPose/import_data/test/models/obj_000004/obj_000004.ply\n",
      "/workspace/CASAPose/import_data/test/models/obj_000005/obj_000005.ply\n",
      "/workspace/CASAPose/import_data/test/models/obj_000006/obj_000006.ply\n",
      "/workspace/CASAPose/import_data/test/models/obj_000007/obj_000007.ply\n",
      "/workspace/CASAPose/import_data/test/models/obj_000008/obj_000008.ply\n",
      "/workspace/CASAPose/import_data/test/models/obj_000009/obj_000009.ply\n",
      "/workspace/CASAPose/import_data/test/models/obj_000010/obj_000010.ply\n",
      "/workspace/CASAPose/import_data/test/models/obj_000011/obj_000011.ply\n",
      "/workspace/CASAPose/import_data/test/models/obj_000012/obj_000012.ply\n",
      "/workspace/CASAPose/import_data/test/models/obj_000013/obj_000013.ply\n",
      "/workspace/CASAPose/import_data/test/models/obj_000014/obj_000014.ply\n",
      "/workspace/CASAPose/import_data/test/models/obj_000015/obj_000015.ply\n",
      "/workspace/CASAPose/import_data/test/models/obj_000016/obj_000016.ply\n",
      "/workspace/CASAPose/import_data/test/test/000001\n"
     ]
    }
   ],
   "source": [
    "test_dataset = VectorfieldDataset(\n",
    "    root=\"/workspace/CASAPose/import_data/test/test\", # Hardcoded param\n",
    "    path_meshes=\"/workspace/CASAPose/import_data/test/models\", # Hardcoded param\n",
    "    path_filter_root=None, # Hardcoded param\n",
    "    color_input=True, # Hardcoded param\n",
    "    no_points=9, # Taken from config_8.ini\n",
    "    objectsofinterest=objectsofinterest,\n",
    "    noise=0.00001,\n",
    "    data_size=None,\n",
    "    save=False, # Hardcoded param\n",
    "    normal=normal_imgs,\n",
    "    contrast=0.00001,\n",
    "    brightness=0.00001,\n",
    "    hue=0.00001,\n",
    "    saturation=0.00001,\n",
    "    random_translation=(0, 0),\n",
    "    random_rotation=0,\n",
    "    random_crop=False,\n",
    "    use_validation_split=use_split,\n",
    "    use_train_split=False,\n",
    "    train_validation_split=None,\n",
    "    output_folder=None,\n",
    "    visibility_filter=False,\n",
    "    separated_vectorfields=(opt.modelname == \"pvnet\"),\n",
    "    wxyz_quaterion_input=opt.datatest_wxyz_quaterion,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89c3770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length:  5\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset length: \", len(test_dataset))\n",
    "testingdata, test_batches = test_dataset.generate_dataset(\n",
    "    1, 1, 0, (480, 640), 1.0, 1, no_objects, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f896c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_vertex_array, mesh_vertex_count = test_dataset.generate_object_vertex_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "908225df",
   "metadata": {},
   "outputs": [],
   "source": [
    "testingdata_iterator = iter(testingdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6add86c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 480, 640, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 480, 640, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 480, 640, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(None, 8, 1, 9, 2), dtype=tf.float32, name=None), TensorSpec(shape=(None, 8, 1, 9, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 3, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 8, 1, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None), TensorSpec(shape=(None, 480, 640, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(None, 8, 1, 8, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 8, 1, 3, 4), dtype=tf.float32, name=None), TensorSpec(shape=(None, 8, 1, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.string, name=None))>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13de8109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 480, 640, 9), dtype=float32, numpy=\n",
       "array([[[[1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingdata_iterator.get_next()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc026f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 11:08:28.723112: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator Assert/Assert\n",
      "2023-03-31 11:08:28.732176: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator Assert_1/Assert\n",
      "2023-03-31 11:08:28.732275: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator Assert_2/Assert\n",
      "2023-03-31 11:08:28.732324: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator Assert_3/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([8, 9, 2]), TensorShape([8, 9, 3]), TensorShape([3, 3])]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "Estimated Coordinates: [[[[374.26462 337.24667]\n",
      "   [352.54822 336.1311 ]\n",
      "   [375.24445 348.34293]\n",
      "   [361.89462 351.3888 ]\n",
      "   [386.0225  329.66934]\n",
      "   [368.78754 331.5153 ]\n",
      "   [370.8289  349.78806]\n",
      "   [362.72827 326.75467]\n",
      "   [381.85168 337.52258]]\n",
      "\n",
      "  [[318.45404 409.8459 ]\n",
      "   [294.55573 406.6304 ]\n",
      "   [342.70773 381.16058]\n",
      "   [294.7497  445.60455]\n",
      "   [315.04025 372.78464]\n",
      "   [317.46225 453.77698]\n",
      "   [283.0346  410.58612]\n",
      "   [323.21164 425.7287 ]\n",
      "   [352.213   398.33746]]\n",
      "\n",
      "  [[  0.        0.     ]\n",
      "   [  0.        0.     ]\n",
      "   [  0.        0.     ]\n",
      "   [  0.        0.     ]\n",
      "   [  0.        0.     ]\n",
      "   [  0.        0.     ]\n",
      "   [  0.        0.     ]\n",
      "   [  0.        0.     ]\n",
      "   [  0.        0.     ]]\n",
      "\n",
      "  [[366.07794 283.95816]\n",
      "   [362.4618  227.53452]\n",
      "   [407.22583 305.69046]\n",
      "   [355.90067 323.29968]\n",
      "   [341.05026 289.85947]\n",
      "   [388.44357 256.68237]\n",
      "   [396.15848 282.5333 ]\n",
      "   [335.8342  305.90555]\n",
      "   [364.77664 254.61748]]\n",
      "\n",
      "  [[  0.        0.     ]\n",
      "   [  0.        0.     ]\n",
      "   [  0.        0.     ]\n",
      "   [  0.        0.     ]\n",
      "   [  0.        0.     ]\n",
      "   [  0.        0.     ]\n",
      "   [  0.        0.     ]\n",
      "   [  0.        0.     ]\n",
      "   [  0.        0.     ]]\n",
      "\n",
      "  [[176.31303 191.41444]\n",
      "   [199.05885 179.75499]\n",
      "   [185.33525 216.90762]\n",
      "   [151.50223 203.16501]\n",
      "   [168.65045 167.79326]\n",
      "   [176.80695 189.31548]\n",
      "   [196.53146 195.18663]\n",
      "   [167.64447 167.72932]\n",
      "   [167.05403 213.62445]]\n",
      "\n",
      "  [[284.6573  205.45396]\n",
      "   [269.12366 231.04993]\n",
      "   [301.43567 182.6103 ]\n",
      "   [271.44318 211.82594]\n",
      "   [284.48688 222.33484]\n",
      "   [270.99503 214.84895]\n",
      "   [294.1286  198.01913]\n",
      "   [274.18066 223.00716]\n",
      "   [276.0589  202.96368]]\n",
      "\n",
      "  [[241.55536 234.7058 ]\n",
      "   [242.55635 270.72314]\n",
      "   [202.15443 222.09703]\n",
      "   [275.31897 257.1108 ]\n",
      "   [226.69073 205.09128]\n",
      "   [256.7347  221.63388]\n",
      "   [219.58815 246.94093]\n",
      "   [263.41986 241.73209]\n",
      "   [243.25539 246.64456]]]]\n",
      "Estimated Poses: [[[[-8.59320879e-01 -1.43020734e-01  4.91032988e-01  1.20489174e+02]\n",
      "   [-4.56204295e-01  6.48345590e-01 -6.09529078e-01  2.35584244e+02]\n",
      "   [-2.31183797e-01 -7.47792184e-01 -6.22383595e-01  1.42022925e+03]]\n",
      "\n",
      "  [[ 8.43016386e-01 -8.95309225e-02  5.30384481e-01 -1.30505705e+01]\n",
      "   [ 3.03262860e-01 -7.35275626e-01 -6.06136680e-01  3.33898376e+02]\n",
      "   [ 4.44246680e-01  6.71828985e-01 -5.92697978e-01  1.14131824e+03]]\n",
      "\n",
      "  [[-0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "   [-0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      "  [[-5.65619826e-01 -6.19882047e-01  5.43893933e-01  1.06522179e+02]\n",
      "   [-7.77425706e-01  1.80789292e-01 -6.02432251e-01  1.07129074e+02]\n",
      "   [ 2.75106698e-01 -7.63584733e-01 -5.84170222e-01  1.48325745e+03]]\n",
      "\n",
      "  [[ 0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "   [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      "  [[-1.12388134e-02  8.48072648e-01  5.29760718e-01 -3.51172394e+02]\n",
      "   [ 6.86630964e-01  3.91687274e-01 -6.12469673e-01 -1.18917610e+02]\n",
      "   [-7.26919293e-01  3.56866717e-01 -5.86715102e-01  1.35057690e+03]]\n",
      "\n",
      "  [[ 7.36181796e-01 -3.37640703e-01  5.86545110e-01 -1.20782349e+02]\n",
      "   [ 1.95810080e-01 -7.23338008e-01 -6.62148774e-01 -1.10560669e+02]\n",
      "   [ 6.47838593e-01  6.02313340e-01 -4.66394901e-01  1.70637598e+03]]\n",
      "\n",
      "  [[ 7.63383746e-01  3.35425138e-01  5.52028298e-01 -2.05115662e+02]\n",
      "   [ 6.41660869e-01 -4.92046356e-01 -5.88355422e-01 -1.67082348e+01]\n",
      "   [ 7.42742717e-02  8.03355932e-01 -5.90849400e-01  1.40426135e+03]]]]\n",
      "Segmentation Masks: [[[[  2.262383  -11.194195   -9.0346    ...  -9.937815  -10.684161\n",
      "     -9.4633   ]\n",
      "   [  2.6248438 -11.561285   -9.287599  ... -10.857949  -10.206826\n",
      "    -10.368701 ]\n",
      "   [  2.7316723 -12.236578   -9.958706  ... -12.0497    -11.189929\n",
      "    -11.287029 ]\n",
      "   ...\n",
      "   [  2.5379953 -11.878326   -7.8726926 ... -11.694892  -10.067402\n",
      "    -12.383358 ]\n",
      "   [  2.5649755 -12.000598   -8.310716  ... -11.558853  -10.290742\n",
      "    -12.196176 ]\n",
      "   [  2.4684596 -11.959714  -10.53995   ... -12.461377  -11.646409\n",
      "    -11.716114 ]]\n",
      "\n",
      "  [[  3.0660312 -12.295154   -9.428665  ... -10.682442  -10.46838\n",
      "     -9.978153 ]\n",
      "   [  4.0088115 -13.638977  -10.666646  ... -12.452308  -10.95823\n",
      "    -12.270824 ]\n",
      "   [  4.153317  -14.429538  -11.4294815 ... -13.832035  -12.107089\n",
      "    -13.324862 ]\n",
      "   ...\n",
      "   [  4.7197337 -14.188172  -10.150626  ... -15.114749  -12.05504\n",
      "    -15.1612   ]\n",
      "   [  4.387688  -13.98079    -9.854017  ... -14.71996   -11.878726\n",
      "    -14.632469 ]\n",
      "   [  3.4150314 -12.732467  -10.7050705 ... -14.215011  -11.948355\n",
      "    -13.324885 ]]\n",
      "\n",
      "  [[  3.125916  -13.0859165  -9.62852   ... -10.626164  -10.349504\n",
      "     -9.662919 ]\n",
      "   [  4.0104413 -14.644847  -10.739119  ... -12.100988  -11.054002\n",
      "    -11.69291  ]\n",
      "   [  4.132415  -15.276037  -11.427008  ... -13.197689  -12.006905\n",
      "    -12.448059 ]\n",
      "   ...\n",
      "   [  4.6075377 -13.773162   -9.436402  ... -13.91574   -11.693026\n",
      "    -14.101432 ]\n",
      "   [  4.310096  -13.484542   -9.331001  ... -13.710988  -11.487228\n",
      "    -13.6625185]\n",
      "   [  3.2671726 -12.325314   -9.672535  ... -13.031702  -11.391197\n",
      "    -12.396853 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  2.7514832 -11.0132     -7.090334  ...  -6.646238   -8.034109\n",
      "     -7.50267  ]\n",
      "   [  3.5604808 -11.614754   -6.860578  ...  -6.3155594  -7.5711517\n",
      "     -8.833394 ]\n",
      "   [  3.5701375 -12.233927   -6.8860483 ...  -6.80491    -7.9600544\n",
      "     -9.1277075]\n",
      "   ...\n",
      "   [  3.041481  -11.938909   -8.593073  ...  -9.624923   -8.42628\n",
      "     -9.520029 ]\n",
      "   [  2.9873586 -11.579612   -8.086454  ...  -9.500182   -7.9853597\n",
      "     -9.486264 ]\n",
      "   [  1.730377  -10.488877   -7.969484  ...  -8.874311   -7.986789\n",
      "     -8.803358 ]]\n",
      "\n",
      "  [[  2.5279765 -10.841448   -6.6760464 ...  -6.065242   -7.292495\n",
      "     -6.8941936]\n",
      "   [  3.6281624 -11.686377   -7.002682  ...  -6.3139725  -7.2188888\n",
      "     -8.523497 ]\n",
      "   [  3.6250894 -12.133607   -6.8987412 ...  -6.5945334  -7.5276775\n",
      "     -8.727322 ]\n",
      "   ...\n",
      "   [  3.053416  -11.598265   -8.170422  ...  -8.721121   -7.5180454\n",
      "     -8.926968 ]\n",
      "   [  3.0542037 -11.217772   -7.9215364 ...  -8.853182   -7.380259\n",
      "     -8.98471  ]\n",
      "   [  1.479925  -10.142144   -7.6562095 ...  -8.184331   -7.475635\n",
      "     -8.433579 ]]\n",
      "\n",
      "  [[  1.8427038  -9.59133    -7.0125093 ...  -7.032141   -8.593568\n",
      "     -7.0744514]\n",
      "   [  2.4907432  -9.677864   -7.0345263 ...  -7.0738316  -7.9505553\n",
      "     -7.517117 ]\n",
      "   [  2.5052285 -10.25843    -7.090792  ...  -7.241149   -8.291925\n",
      "     -7.884899 ]\n",
      "   ...\n",
      "   [  1.7669358  -9.751762   -7.6364794 ...  -8.084003   -7.80643\n",
      "     -7.9356275]\n",
      "   [  1.5512607  -9.590808   -7.5033937 ...  -8.11733    -7.6949773\n",
      "     -8.142701 ]\n",
      "   [  0.9847558  -9.941799   -7.7860703 ...  -8.218224   -8.76555\n",
      "     -8.71888  ]]]]\n",
      "Image: <class 'numpy.ndarray'>\n",
      "Objects of Interest: ['obj_000001', 'obj_000005', 'obj_000006', 'obj_000008', 'obj_000009', 'obj_000010', 'obj_000011', 'obj_000016']\n",
      "length: 8\n",
      "Number of Objects: 9\n"
     ]
    }
   ],
   "source": [
    "img = runnetwork(testingdata_iterator, int(test_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50419d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af221ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"final_image.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb1e2da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a42aa35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
