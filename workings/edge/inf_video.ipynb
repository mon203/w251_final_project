{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfe74c1b-aabc-46bf-8ff0-68c749376f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94ea0b73-b3a0-432b-a062-285667dccf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "350cb04b-a557-47ef-a1fc-c7ca53644633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames per second = 30.00706259418286\n",
      "total frame counts = 558.0\n",
      "duration = 18.59562222222222 sec\n"
     ]
    }
   ],
   "source": [
    "# Get an idea of video's parameter\n",
    "video = cv2.VideoCapture('headphones.mp4')\n",
    "\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "print('frames per second =',fps)\n",
    "\n",
    "frame_count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "print('total frame counts =',frame_count)\n",
    "\n",
    "duration = frame_count/fps\n",
    "print('duration =', duration, 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26251a84-48cc-4adf-88b3-2e88cb5c97cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input variables\n",
    "pathIn = 'headphones.mp4'\n",
    "pathOut = 'inference_output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cce2c88c-359c-464c-8ebd-471de6ab74d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(pathOut): \n",
    "    os.makedirs(pathOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0429021e-85aa-4aaf-b473-08ded2b35a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf083976d58403e830ed6056500f129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# video to inference image frames\n",
    "pbar = tqdm(total=int(frame_count))\n",
    "\n",
    "def extractImages(pathIn, pathOut):\n",
    "    count = 0\n",
    "    vidcap = cv2.VideoCapture(pathIn)\n",
    "    while vidcap.isOpened():\n",
    "        ret, image = vidcap.read()\n",
    "        if ret:\n",
    "            count += 1\n",
    "            pbar.update(1)\n",
    "            # do inference here\n",
    "            # inferenced_img = inference(image)\n",
    "            cv2.imwrite(pathOut + '%04d.png' % count, image)\n",
    "        else:\n",
    "            break\n",
    "    vidcap.release()\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3382cd1-4d61-42b0-b951-acbc6b96f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractImages(pathIn, pathOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "151aeb34-0ad8-4022-b874-699da248120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the inference video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50ab3a24-e464-4dba-b781-bec26bec92c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildVideo(dataPath):\n",
    "    img_array = []\n",
    "    for filename in tqdm(sorted(glob.glob(dataPath + '*.png'))):\n",
    "        img = cv2.imread(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "        img_array.append(img)\n",
    "    out = cv2.VideoWriter(dataPath + 'inference.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, size)\n",
    "    #out = cv2.VideoWriter('inference.mp4', cv2.VideoWriter_fourcc(*'x264'), fps, size)\n",
    "\n",
    "    \n",
    "    for i in range(len(img_array)):\n",
    "        out.write(img_array[i])\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de5a6719-6f6d-41b9-bdb1-c55177d69ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2487df83ac834ff98676e9e85327793d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "buildVideo(pathOut)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
